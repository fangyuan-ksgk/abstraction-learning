{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment (I). Hiearhical Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Hierarchical Sequence K=2 L=3 (aligned by timestamp):\n",
      "-------------------------------------------------------\n",
      "Level 2:                 [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2] \n",
      "Level 1:         [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1] \n",
      "Level 0:     [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] \n",
      "=======================================================\n",
      "Total tokens: 350, Max timestamp: 200\n",
      "\n",
      "Epoch 1/30, Loss: 4.158883571624756\n",
      "Epoch 2/30, Loss: 3.987037420272827\n",
      "Epoch 3/30, Loss: 3.74379563331604\n",
      "Epoch 4/30, Loss: 3.527414321899414\n",
      "Epoch 5/30, Loss: 3.318906784057617\n",
      "Epoch 6/30, Loss: 3.1103715896606445\n",
      "Epoch 7/30, Loss: 2.903388261795044\n",
      "Epoch 8/30, Loss: 2.699125289916992\n",
      "Epoch 9/30, Loss: 2.49737286567688\n",
      "Epoch 10/30, Loss: 2.2964634895324707\n",
      "Epoch 11/30, Loss: 2.096004009246826\n",
      "Epoch 12/30, Loss: 1.8935136795043945\n",
      "Epoch 13/30, Loss: 1.7067910432815552\n",
      "Epoch 14/30, Loss: 1.5114589929580688\n",
      "Epoch 15/30, Loss: 1.3093849420547485\n",
      "Epoch 16/30, Loss: 1.156589150428772\n",
      "Epoch 17/30, Loss: 1.0025535821914673\n",
      "Epoch 18/30, Loss: 0.8656474947929382\n",
      "Epoch 19/30, Loss: 0.7505219578742981\n",
      "Epoch 20/30, Loss: 0.6471614241600037\n",
      "Epoch 21/30, Loss: 0.5491518378257751\n",
      "Epoch 22/30, Loss: 0.46484485268592834\n",
      "Epoch 23/30, Loss: 0.39563462138175964\n",
      "Epoch 24/30, Loss: 0.33726969361305237\n",
      "Epoch 25/30, Loss: 0.28673091530799866\n",
      "Epoch 26/30, Loss: 0.2428400069475174\n",
      "Epoch 27/30, Loss: 0.2045609951019287\n",
      "Epoch 28/30, Loss: 0.17239819467067719\n",
      "Epoch 29/30, Loss: 0.14576207101345062\n",
      "Epoch 30/30, Loss: 0.13522891700267792\n"
     ]
    }
   ],
   "source": [
    "# The issue with this counting sequence is that it has batch size of 1 only \n",
    "# it's fine for now, but clearly a fourier series decomposition is more beautiful\n",
    "\n",
    "# (I). Counting Sequence\n",
    "# --------------------------------------------------------------------------------\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "# (I.1) Generate Counting Sequence\n",
    "# ----------------------------------------------------\n",
    "def generate_level(l: int, seq: list, t: int, L: int, K: int): \n",
    "    if l < L:\n",
    "        seq[l] += str(l)\n",
    "        if t % K == 0: \n",
    "            return generate_level(l+1, seq, t // K, L, K)\n",
    "    return seq\n",
    "\n",
    "def generate_count_seq(L: int, K: int, T: int): \n",
    "    seq = defaultdict(str)\n",
    "    for t in range(1, T+1): \n",
    "        seq = generate_level(0, seq, t, L, K)\n",
    "    return seq\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# (I.2) Tokenizer (basic integer tokenizer)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "class TinyTokenizer: \n",
    "    def __init__(self, vocab: dict):\n",
    "        self.vocab = {str(k): v for k, v in vocab.items()}\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "    def __call__(self, seq: str):\n",
    "        return [self.vocab[c] for c in seq]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "# (I.3) Tensor idx sequence preparation \n",
    "# ----------------------------------------------------\n",
    "\n",
    "L = 3\n",
    "K = 2\n",
    "T = 200\n",
    "\n",
    "data = generate_count_seq(L, K, T)\n",
    "tokenizer = TinyTokenizer({str(k): k for k in range(10)})\n",
    "\n",
    "idx = [tokenizer(seq) for seq in data.values()]\n",
    "idx += [[] for _ in range(L - len(idx))]\n",
    "samples = [(idx, None)]\n",
    "\n",
    "from model import GATConfig, GAT, HierSeq\n",
    "from utils import stream_print_hseq\n",
    "from torch.optim import Adam \n",
    "\n",
    "config = GATConfig(K=K, L=L, n_embd=128, n_head=4, device=\"cpu\", _compile=False)\n",
    "gat = GAT(config)\n",
    "\n",
    "# .from_hiearchical_data has error: prepared token is NOT interleaved with correct causal ordering\n",
    "batch_data = HierSeq.from_hierarchical_data(samples, K=gat.K, L=gat.L)\n",
    "stream_print_hseq(batch_data) # sanity check\n",
    "\n",
    "# Batched Forward Propagation\n",
    "epochs = 30\n",
    "# gat.train()\n",
    "\n",
    "\n",
    "# Training Loop : learning just fine -- loss reduces quickly\n",
    "# ----------------------------------------------------\n",
    "optimizer = Adam(gat.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = gat(batch_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "    # break\n",
    "# ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Hierarchical Sequence K=2 L=3 (aligned by timestamp):\n",
      "-------------------------------------------------------\n",
      "Level 2:                 [2]             [2]             [2]                 \n",
      "Level 1:         [1]     [1]     [1]     [1]     [1]     [1]     [1]         \n",
      "Level 0:     [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] \n",
      "=======================================================\n",
      "Total tokens: 26, Max timestamp: 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import * \n",
    "\n",
    "\n",
    "test_data = generate_count_seq(L, K, 1)\n",
    "idx = [tokenizer(seq) for seq in test_data.values()]\n",
    "idx += [[] for _ in range(L - len(idx))]\n",
    "test_samples = [(idx, None)]\n",
    "test_batch_data = HierSeq.from_hierarchical_data(test_samples, K=gat.K, L=gat.L)\n",
    "\n",
    "\n",
    "for _ in range(25): \n",
    "    gat.generate(test_batch_data)\n",
    "    stream_print_hseq(test_batch_data)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-Organizing Reinforcement Learning\n",
    "1. A more exciting question is how can I build a GAT module for a Snake game? It'll be the natural test-bed for SoRL -- a snake with inner-monologue. \n",
    "2. Decision Abstractive Transformer (DAT).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Episode 0: Score=0, Reward=-11.0\n",
      "Episode 1: Score=0, Reward=-10.9\n",
      "Episode 2: Score=0, Reward=-10.9\n",
      "Episode 3: Score=1, Reward=-0.7999999999999989\n",
      "Episode 4: Score=0, Reward=-13.200000000000001\n",
      "Sanity check passed: total 153 0-th level tokens (state & action)\n",
      "Sanity check passed: 79 state tokens in data, 79 state tokens in trajectories\n",
      "Sanity check passed: 74 action tokens in data, 74 action tokens in trajectories\n",
      "Sanity check passed: 183 (action/state/abstract) tokens in data\n"
     ]
    }
   ],
   "source": [
    "from snake import SnakeGameEngine, collect_trajectories, RandomAgent\n",
    "from utils import HierTraj, data_sanity_check\n",
    "from constant import PLACE_HOLDER_STATE_TOK, PLACE_HOLDER_ACTION_TOK\n",
    "\n",
    "env = SnakeGameEngine(width=10, height=10)\n",
    "\n",
    "# This is a make-shift data collection pipeline, the abstract tokens are complete false. \n",
    "# The proper way to collect data, per SoRL, is to 'simulate' multiple actions on the environment and store the HierTraj state directly\n",
    "# in that sense, the code snippet in the middle is not useful...\n",
    "\n",
    "# A way to use 'expert trajectory' is to take in the 'trajectories', and have the agent 'learn / explore' on what abstract tokens can be \n",
    "# used to explain the trajectory. This is very similar to the 'intuitive-physics' based 'learning by surprise' or 'active learning from obs' \n",
    "# idea. \n",
    "\n",
    "# For what is worth, the mid-snippet is useless (besides serving as a toy-case on which we test on SSL training of GAT)\n",
    "\n",
    "# Collect trajectories\n",
    "trajectories = collect_trajectories(env, RandomAgent(env), num_episodes=5, device=\"cpu\")\n",
    "\n",
    "samples = []\n",
    "for trajectory in trajectories: \n",
    "\n",
    "    n_state = trajectory[0].size(0)\n",
    "    placeholder_tokens = [PLACE_HOLDER_STATE_TOK if i % 2 == 0 else PLACE_HOLDER_ACTION_TOK for i in range(2*n_state-1)]\n",
    "    sample = ([placeholder_tokens, [3, 9, 4, 2], [19, 14]], None)\n",
    "    samples.append(sample)\n",
    "\n",
    "batch_data = HierTraj.from_hierarchical_data(samples, K=3, L=3)\n",
    "data_sanity_check(batch_data, trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DAT, DATConfig\n",
    "\n",
    "# DAT model \n",
    "\n",
    "config = DATConfig(\n",
    "    n_layer=4,\n",
    "    n_head=2,\n",
    "    n_embd=32,\n",
    "    K=2,\n",
    "    L=3,\n",
    "    vocab_size_list=[64, 32],\n",
    "    device=\"cpu\",\n",
    "    _compile=True,\n",
    ")\n",
    "\n",
    "# Snake specific encoder & decoder for state & action\n",
    "from snake import StateEncoder, StateDecoder, ActionEncoder, ActionDecoder\n",
    "\n",
    "state_encoder = StateEncoder(height=10, width=10, feature_dim=config.n_embd)\n",
    "state_decoder = StateDecoder(height=10, width=10, feature_dim=config.n_embd)\n",
    "action_encoder = ActionEncoder(action_size=4, feature_dim=config.n_embd)\n",
    "action_decoder = ActionDecoder(action_size=4, feature_dim=config.n_embd)\n",
    "\n",
    "dat = DAT(config, state_encoder, state_decoder, action_encoder, action_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss\n",
    "loss = dat(batch_data, trajectories)\n",
    "\n",
    "# generate & update \n",
    "new_batch_data, new_trajectories = dat.generate(batch_data, trajectories)\n",
    "\n",
    "# act: produce action tokens (if there already exists action-tokens un-grounded with reward, skip it)\n",
    "pairs = dat.act(batch_data, trajectories) # list of (sample_idx, action_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Hierarchical Trajectory K=2 L=3 (aligned by timestamp):\n",
      "-------------------------------------------------------\n",
      "Level 2:              [0]     \n",
      "Level 1:      [0]     [0]     \n",
      "L0-State: [s] [s] [s] [s]     \n",
      "L0-Action:    [a] [a] [a] [a] \n",
      "=======================================================\n",
      "Total tokens: 11, Max timestamp: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate on 'order of generation'\n",
    "from utils import test_dat_gen_order\n",
    "\n",
    "# Sanity check-up function (order of generation)\n",
    "test_dat_gen_order(dat, env, L=3, K=2, n_gen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2x2 visualization for first 4 samples\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "from vis import visualize_backtrack\n",
    "from utils import * \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create 2x2 subplot figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Backtrack Visualization for First 4 Samples', fontsize=16)\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "# Process first 4 samples\n",
    "num_samples = min(4, batch_data.indices.max().item() + 1)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample_idx = i\n",
    "    \n",
    "    # Get sample-level perplexity data\n",
    "    per_sample_ppt, per_sample_timestamps, max_abs_ts = get_sample_level_ppl(batch_data, ppt, level=0)\n",
    "    \n",
    "    # Extract data for current sample\n",
    "    sample_timestamps = per_sample_timestamps[sample_idx][:max_abs_ts + batch_data.K]\n",
    "    sample_ppt = per_sample_ppt[sample_idx][:max_abs_ts + batch_data.K]\n",
    "    \n",
    "    # Select current subplot\n",
    "    ax = axes_flat[i]\n",
    "    \n",
    "    # Plot the data\n",
    "    ax.plot(sample_timestamps.cpu().numpy(), sample_ppt.cpu().numpy(), \n",
    "            'b-', linewidth=1.5, label='Perplexity')\n",
    "    \n",
    "    # Add threshold line\n",
    "    ax.axhline(y=buffer.ppl_thres, color='r', linestyle='--', \n",
    "               linewidth=1, label=f'Threshold ({buffer.ppl_thres:.2f})')\n",
    "    \n",
    "    # Mark critical timestamps\n",
    "    critical_mask = sample_ppt > buffer.ppl_thres\n",
    "    if critical_mask.any():\n",
    "        critical_ts = sample_timestamps[critical_mask]\n",
    "        critical_ppt = sample_ppt[critical_mask]\n",
    "        ax.scatter(critical_ts.cpu().numpy(), critical_ppt.cpu().numpy(), \n",
    "                  color='red', s=50, zorder=5, label='Critical Points')\n",
    "    \n",
    "    # Mark backtrack points (where cts changed for this sample)\n",
    "    if sample_idx < len(cts):\n",
    "        backtrack_ts = cts[sample_idx] + 1\n",
    "        if backtrack_ts > 0:\n",
    "            ax.axvline(x=backtrack_ts, color='green', linestyle=':', \n",
    "                      linewidth=1.5, label=f'Backtrack (t={backtrack_ts})')\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_xlabel('Timestamp', fontsize=10)\n",
    "    ax.set_ylabel('Perplexity', fontsize=10)\n",
    "    ax.set_title(f'Sample {sample_idx}', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=8, loc='upper right')\n",
    "    \n",
    "    # Set y-axis limits for better visualization\n",
    "    ax.set_ylim([0, max(10, sample_ppt.max().item() * 1.1)])\n",
    "\n",
    "# Hide unused subplots if less than 4 samples\n",
    "for i in range(num_samples, 4):\n",
    "    axes_flat[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Visualized {num_samples} samples in 2x2 grid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the new helper function for cleaner multi-sample visualization\n",
    "from vis import visualize_multi_sample_backtrack\n",
    "\n",
    "# Create 2x2 grid visualization for first 4 samples\n",
    "fig, axes = visualize_multi_sample_backtrack(batch_data, ppt, cts, buffer, num_samples=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Does DAT dream of playing snake game?\n",
    "\n",
    "# from agent import HiearchicalAgent\n",
    "from snake import SnakeGameEngine\n",
    "from utils import draw_gif\n",
    "from agent import collect_dat_game_play_frames\n",
    "from agent import HiearchicalAgent\n",
    "\n",
    "# Environment\n",
    "env = SnakeGameEngine(width=10, height=10)\n",
    "\n",
    "# DAT Agent (Snake specific agent)\n",
    "# agent = HiearchicalAgent(dat, env.reset(), \"cpu\")\n",
    "\n",
    "# DAT plays the snake game\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "epsilon = 0.9\n",
    "frames = collect_dat_game_play_frames(dat, env, epsilon=epsilon)\n",
    "draw_gif(frames, txt=f\"DAT (randomized) play Snake (epsilon={epsilon})\", path=\"./visual/dat_snake.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Algorithm\n",
    "\n",
    "- Learn to Explain (GAT)\n",
    "Trajectory only data --> Sample --> Train\n",
    "\n",
    "- Learn to Explore (DAT)\n",
    "No data --> Sample --> Extend & Environment Interaction --> Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crazier idea; \n",
    "- number of learning step matters, when it's big, we get more instability, but better search ability improvement\n",
    "- when we have 'similar abstractions', we want to 'learn more'\n",
    "- when we have 'dis-similar abstraction' (picked one has clear advantage) -- do we 'learn less'? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment on SSL for abstract & trajectory tokens \n",
    "\n",
    "(temperature=0.0, data_size=1)\n",
    "1. Simply pick any abstraction (entire sequence), and train with ssl (abstract & trajectory) works for improving 'search ability'. \n",
    "- Improve ppl percentage: 25% / 21% / 7% --- traj loss ~ 1.3 / 1.3\n",
    "2. Add one abstract token (pin-down one option and train with abstract / trajectory ssl loss)\n",
    "- Improve ppl percentage: 18% / 17% -- traj loss ~0.5 / 0.529\n",
    "3. I increment 't_search' with a curriculum design following: 3->6->9->12->15->None\n",
    "- Improve ppl percentage: 69% -- traj loss ~ 0.5 | the learning is very much transferrable, the last lesson has a bigger jump, but it has a small initial abs_loss, whilst the ssl_loss decreases very fast, too. I suspect this is a better strategy for ssl & improve_ppl_percentage\n",
    "\n",
    "$\\textit{Remark 1}$: The excitement here, is that for the first time, we've verifed that JUST TRAIN with ssl works to improve traj_loss with SPECIFIC abs token choice made BY THE POLICY model)\n",
    "\n",
    "(temperature=0.0, data_size=3)\n",
    "1. one abstract token (picked and pinned), train with abstract / trajectory ssl loss\n",
    "- Improve ppl percentage: 25% | traj loss ~ 0.76\n",
    "\n",
    "\n",
    "\n",
    "So obviously, we should perform incremental search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compare SoRL v3 with baseline transformer | evaluate on OOD case\n",
    "2. Evaluate SoRL v3 on arithmetic dataset, where evaluation etc. are more obvious and straight-forward \n",
    "3. Put things on GPU device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{SoRL (GAT)}$\n",
    "1. Group advantage computation \n",
    "2. Surrogate loss computation\n",
    "\n",
    "The key for learning from experience is learning from failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating circular with n=2, n_context=3...\n",
      "Saved 100 sequences to dataset/nbody/2body_100.bin\n"
     ]
    }
   ],
   "source": [
    "from dataset.nbody import NBodyDataset \n",
    "\n",
    "dataset = NBodyDataset(\n",
    "    n_bodies=2,\n",
    "    patterns=['circular'],\n",
    "    T=20,\n",
    "    filepath='dataset/nbody/2body_100.bin',\n",
    "    num_data=100,\n",
    "    K=3, \n",
    "    L=2\n",
    ").build()\n",
    "\n",
    "# dataset.sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 587437.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 sequences to dataset/multiplication/50-123.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset.arithmetic import ArithmeticDataset\n",
    "\n",
    "val_dataset = ArithmeticDataset(\n",
    "    min_digit=1,\n",
    "    max_digit=3,\n",
    "    num_data = 50,\n",
    "    filepath=\"dataset/multiplication/50-123.bin\"\n",
    ").build()\n",
    "\n",
    "# dataset = ArithmeticDataset(\n",
    "#     min_digit=1,\n",
    "#     max_digit=3,\n",
    "#     num_data=100000,\n",
    "#     filepath=\"dataset/multiplication/100K-123.bin\"\n",
    "# ).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn-to-explain (GAT) | one batch ver.\n",
    "\n",
    "# (1). Initialize Data Buffer with trajectory-only data \n",
    "\n",
    "from model import GATConfig, GAT\n",
    "from dataset.arithmetic import ArithmeticDataset\n",
    "\n",
    "from dataclasses import asdict\n",
    "from search import SORLConfig \n",
    "import wandb\n",
    "\n",
    "gat_config = GATConfig(K=3, L=2, n_embd=128, n_head=4, n_layer=4, device=\"cpu\", _compile=False,\n",
    "                       vocab_size_list=[17, 8])\n",
    "gat = GAT(gat_config)\n",
    "\n",
    "\n",
    "config = SORLConfig(gat_config=gat_config, \n",
    "           n_generations=4, temperature=1.0, num_iterations=2, \n",
    "           joint_steps=10, context_length=1024, learning_rate=1e-3,\n",
    "           dataset_name=\"100K-123\", \n",
    "           dataset_path=\"dataset/multiplication/100K-123.bin\",\n",
    "           id_validate_dataset_path=\"dataset/multiplication/2k-123.bin\",\n",
    "           ood_validate_dataset_path=\"dataset/multiplication/2k-123.bin\")\n",
    "\n",
    "# load dataset\n",
    "dataset = ArithmeticDataset.from_file(config.dataset_path)\n",
    "id_val_dataset = ArithmeticDataset.from_file(config.id_validate_dataset_path)\n",
    "\n",
    "\n",
    "# gat.load_checkpoint(\"experiment/nbody/SoRL-GRPO-per-token-alternate-nbody.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Including window of size 100 & 0.1 abstraction switch ratio + search annealing phase change (with no return tickets). \n",
    "- search phase collapse the search advantage from 20 percent to 2 ~ 6 percent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.0\n",
      "Iteration 1/200Joint iter 1/1, loss: 2.8332, abs_loss: 0.0000, ssl_loss: 2.8332\n",
      "\n",
      "Improve ppl percentage (train): 0.0000\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 1 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 30, ratio: 1.0000\n",
      " - average advantage over greedy choice: 0.0015\n",
      "Threshold increased to 0.0006239890935830772\n",
      "Iteration 2/200Joint iter 1/1, loss: 4.8680, abs_loss: 2.0794, ssl_loss: 2.7886\n",
      "\n",
      "Improve ppl percentage (train): 0.0528\n",
      "per-sample abstraction switch ratio: 1.0000 | t_search: 2 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1600\n",
      " - average advantage over greedy choice: 0.0017\n",
      "Threshold decreased to 0.0004746007907669991\n",
      "Iteration 3/200Joint iter 1/1, loss: 4.7327, abs_loss: 1.9868, ssl_loss: 2.7459\n",
      "\n",
      "Improve ppl percentage (train): 0.1244\n",
      "per-sample abstraction switch ratio: 0.1600 | t_search: 3 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 4.746008198708296e-05\n",
      "Iteration 4/200Joint iter 1/1, loss: 4.5534, abs_loss: 1.8677, ssl_loss: 2.6857\n",
      "\n",
      "Improve ppl percentage (train): 0.1655\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 4 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 8, ratio: 0.2963\n",
      " - average advantage over greedy choice: 0.0011\n",
      "Threshold increased to 0.0004336419515311718\n",
      "Iteration 5/200Joint iter 1/1, loss: 4.4376, abs_loss: 1.8132, ssl_loss: 2.6244\n",
      "\n",
      "Improve ppl percentage (train): 0.3043\n",
      "per-sample abstraction switch ratio: 0.2963 | t_search: 5 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 6, ratio: 0.2143\n",
      " - average advantage over greedy choice: 0.0020\n",
      "Threshold increased to 0.0005875307833775878\n",
      "Iteration 6/200Joint iter 1/1, loss: 4.2368, abs_loss: 1.6702, ssl_loss: 2.5666\n",
      "\n",
      "Improve ppl percentage (train): 0.6901\n",
      "per-sample abstraction switch ratio: 0.2143 | t_search: 6 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 7, ratio: 0.2593\n",
      " - average advantage over greedy choice: 0.0025\n",
      "Threshold increased to 0.0007257863180711865\n",
      "Iteration 7/200Joint iter 1/1, loss: 4.0557, abs_loss: 1.5469, ssl_loss: 2.5089\n",
      "\n",
      "Improve ppl percentage (train): 0.7090\n",
      "per-sample abstraction switch ratio: 0.2593 | t_search: 7 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.1923\n",
      " - average advantage over greedy choice: 0.0046\n",
      "Threshold decreased to 2.5272369384765625e-05\n",
      "Iteration 8/200Joint iter 1/1, loss: 3.9657, abs_loss: 1.4701, ssl_loss: 2.4956\n",
      "\n",
      "Improve ppl percentage (train): 1.2782\n",
      "per-sample abstraction switch ratio: 0.1923 | t_search: 8 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 6, ratio: 0.2308\n",
      " - average advantage over greedy choice: 0.0051\n",
      "Threshold increased to 0.001789908274076879\n",
      "Iteration 9/200Joint iter 1/1, loss: 3.7858, abs_loss: 1.3495, ssl_loss: 2.4363\n",
      "\n",
      "Improve ppl percentage (train): 1.4396\n",
      "per-sample abstraction switch ratio: 0.2308 | t_search: 9 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 8, ratio: 0.3200\n",
      " - average advantage over greedy choice: 0.0130\n",
      "Threshold increased to 0.005612931679934263\n",
      "Iteration 10/200Joint iter 1/1, loss: 3.8725, abs_loss: 1.4509, ssl_loss: 2.4216\n",
      "\n",
      "Improve ppl percentage (train): 2.0701\n",
      "per-sample abstraction switch ratio: 0.3200 | t_search: 10 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.2000\n",
      " - average advantage over greedy choice: 0.0212\n",
      "Iteration 11/200Joint iter 1/1, loss: 3.5863, abs_loss: 1.2196, ssl_loss: 2.3667\n",
      "\n",
      "Improve ppl percentage (train): 2.5883\n",
      "per-sample abstraction switch ratio: 0.2000 | t_search: 11 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.1923\n",
      " - average advantage over greedy choice: 0.0328\n",
      "Threshold decreased to 0.0035790749825537205\n",
      "Iteration 12/200Joint iter 1/1, loss: 3.3411, abs_loss: 1.0309, ssl_loss: 2.3102\n",
      "\n",
      "Improve ppl percentage (train): 0.4566\n",
      "per-sample abstraction switch ratio: 0.1923 | t_search: 12 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 7, ratio: 0.2917\n",
      " - average advantage over greedy choice: 0.1008\n",
      "Threshold increased to 0.02614196017384529\n",
      "Iteration 13/200Joint iter 1/1, loss: 3.4104, abs_loss: 1.0144, ssl_loss: 2.3960\n",
      "\n",
      "Improve ppl percentage (train): 0.4783\n",
      "per-sample abstraction switch ratio: 0.2917 | t_search: 13 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 7, ratio: 0.2593\n",
      " - average advantage over greedy choice: 0.1771\n",
      "Threshold increased to 0.04420740529894829\n",
      "Iteration 14/200Joint iter 1/1, loss: 3.1840, abs_loss: 0.8468, ssl_loss: 2.3372\n",
      "\n",
      "Improve ppl percentage (train): 3.3452\n",
      "per-sample abstraction switch ratio: 0.2593 | t_search: 14 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0632\n",
      "Threshold decreased to 0.01578824408352375\n",
      "Iteration 15/200Joint iter 1/1, loss: 2.9699, abs_loss: 0.6960, ssl_loss: 2.2740\n",
      "\n",
      "Improve ppl percentage (train): 3.9781\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1538\n",
      " - average advantage over greedy choice: 0.0407\n",
      "Threshold decreased to 0.009634378366172314\n",
      "Iteration 16/200Joint iter 1/1, loss: 2.9081, abs_loss: 0.6510, ssl_loss: 2.2571\n",
      "\n",
      "Improve ppl percentage (train): 3.5945\n",
      "per-sample abstraction switch ratio: 0.1538 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.1923\n",
      " - average advantage over greedy choice: 0.0538\n",
      "Threshold decreased to 0.005926001816987991\n",
      "Iteration 17/200Joint iter 1/1, loss: 2.9654, abs_loss: 0.7638, ssl_loss: 2.2016\n",
      "\n",
      "Improve ppl percentage (train): 4.6556\n",
      "per-sample abstraction switch ratio: 0.1923 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.1923\n",
      " - average advantage over greedy choice: 0.0500\n",
      "Threshold decreased to 6.133085116744041e-05\n",
      "Iteration 18/200Joint iter 1/1, loss: 2.8229, abs_loss: 0.6318, ssl_loss: 2.1911\n",
      "\n",
      "Improve ppl percentage (train): 6.4402\n",
      "per-sample abstraction switch ratio: 0.1923 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1538\n",
      " - average advantage over greedy choice: 0.0294\n",
      "Threshold decreased to 0.0\n",
      "Iteration 19/200Joint iter 1/1, loss: 2.8460, abs_loss: 0.6527, ssl_loss: 2.1932\n",
      "\n",
      "Improve ppl percentage (train): 6.4031\n",
      "per-sample abstraction switch ratio: 0.1538 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 9, ratio: 0.3462\n",
      " - average advantage over greedy choice: 0.0268\n",
      "Threshold increased to 0.017232956364750862\n",
      "Iteration 20/200Joint iter 1/1, loss: 2.8196, abs_loss: 0.6488, ssl_loss: 2.1708\n",
      "\n",
      "Improve ppl percentage (train): 6.0376\n",
      "per-sample abstraction switch ratio: 0.3462 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.1852\n",
      " - average advantage over greedy choice: 0.0884\n",
      "Threshold decreased to 0.01182469166815281\n",
      "Iteration 21/200Joint iter 1/1, loss: 2.6963, abs_loss: 0.5530, ssl_loss: 2.1433\n",
      "\n",
      "Improve ppl percentage (train): 5.8899\n",
      "per-sample abstraction switch ratio: 0.1852 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 8, ratio: 0.3200\n",
      " - average advantage over greedy choice: 0.0631\n",
      "Threshold increased to 0.0180034376680851\n",
      "Iteration 22/200Joint iter 1/1, loss: 2.8745, abs_loss: 0.7252, ssl_loss: 2.1492\n",
      "\n",
      "Improve ppl percentage (train): 5.9586\n",
      "per-sample abstraction switch ratio: 0.3200 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1600\n",
      " - average advantage over greedy choice: 0.0575\n",
      "Threshold decreased to 0.016085531562566757\n",
      "Iteration 23/200Joint iter 1/1, loss: 2.5171, abs_loss: 0.3564, ssl_loss: 2.1608\n",
      "\n",
      "Improve ppl percentage (train): 4.7647\n",
      "per-sample abstraction switch ratio: 0.1600 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 7, ratio: 0.2800\n",
      " - average advantage over greedy choice: 0.0613\n",
      "Threshold increased to 0.01615033484995365\n",
      "Iteration 24/200Joint iter 1/1, loss: 2.7176, abs_loss: 0.5753, ssl_loss: 2.1423\n",
      "\n",
      "Improve ppl percentage (train): 7.2738\n",
      "per-sample abstraction switch ratio: 0.2800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0769\n",
      " - average advantage over greedy choice: 0.0772\n",
      "Threshold decreased to 0.013760725036263466\n",
      "Iteration 25/200Joint iter 1/1, loss: 2.4302, abs_loss: 0.3011, ssl_loss: 2.1291\n",
      "\n",
      "Improve ppl percentage (train): 6.5799\n",
      "per-sample abstraction switch ratio: 0.0769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 6, ratio: 0.2308\n",
      " - average advantage over greedy choice: 0.0712\n",
      "Threshold increased to 0.019202720373868942\n",
      "Iteration 26/200Joint iter 1/1, loss: 2.5565, abs_loss: 0.4399, ssl_loss: 2.1166\n",
      "\n",
      "Improve ppl percentage (train): 7.3483\n",
      "per-sample abstraction switch ratio: 0.2308 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0370\n",
      " - average advantage over greedy choice: 0.0762\n",
      "Threshold decreased to 0.015628762543201447\n",
      "Iteration 27/200Joint iter 1/1, loss: 2.3426, abs_loss: 0.2536, ssl_loss: 2.0890\n",
      "\n",
      "Improve ppl percentage (train): 9.9507\n",
      "per-sample abstraction switch ratio: 0.0370 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 6, ratio: 0.2400\n",
      " - average advantage over greedy choice: 0.0726\n",
      "Threshold increased to 0.017765415832400322\n",
      "Iteration 28/200Joint iter 1/1, loss: 2.4717, abs_loss: 0.3499, ssl_loss: 2.1217\n",
      "\n",
      "Improve ppl percentage (train): 8.6087\n",
      "per-sample abstraction switch ratio: 0.2400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 8, ratio: 0.3333\n",
      " - average advantage over greedy choice: 0.0757\n",
      "Threshold increased to 0.01807381585240364\n",
      "Iteration 29/200Joint iter 1/1, loss: 2.5883, abs_loss: 0.4067, ssl_loss: 2.1815\n",
      "\n",
      "Improve ppl percentage (train): 7.5973\n",
      "per-sample abstraction switch ratio: 0.3333 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1538\n",
      " - average advantage over greedy choice: 0.0866\n",
      "Threshold decreased to 0.015535067766904831\n",
      "Iteration 30/200Joint iter 1/1, loss: 2.3677, abs_loss: 0.2481, ssl_loss: 2.1196\n",
      "\n",
      "Improve ppl percentage (train): 8.6349\n",
      "per-sample abstraction switch ratio: 0.1538 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 3, ratio: 0.1154\n",
      " - average advantage over greedy choice: 0.0770\n",
      "Threshold decreased to 0.01407268363982439\n",
      "Iteration 31/200Joint iter 1/1, loss: 2.3624, abs_loss: 0.2687, ssl_loss: 2.0937\n",
      "\n",
      "Improve ppl percentage (train): 9.5509\n",
      "per-sample abstraction switch ratio: 0.1154 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 3, ratio: 0.1111\n",
      " - average advantage over greedy choice: 0.0980\n",
      "Threshold decreased to 0.006298186257481575\n",
      "Iteration 32/200Joint iter 1/1, loss: 2.2806, abs_loss: 0.2450, ssl_loss: 2.0356\n",
      "\n",
      "Improve ppl percentage (train): 11.4950\n",
      "per-sample abstraction switch ratio: 0.1111 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0800\n",
      " - average advantage over greedy choice: 0.0910\n",
      "Threshold decreased to 0.0\n",
      "Iteration 33/200Joint iter 1/1, loss: 2.2905, abs_loss: 0.1823, ssl_loss: 2.1082\n",
      "\n",
      "Improve ppl percentage (train): 10.5776\n",
      "per-sample abstraction switch ratio: 0.0800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 13, ratio: 0.4815\n",
      " - average advantage over greedy choice: 0.0357\n",
      "Threshold increased to 0.018805332481861115\n",
      "Iteration 34/200Joint iter 1/1, loss: 2.6138, abs_loss: 0.5586, ssl_loss: 2.0551\n",
      "\n",
      "Improve ppl percentage (train): 11.3484\n",
      "per-sample abstraction switch ratio: 0.4815 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1481\n",
      " - average advantage over greedy choice: 0.0777\n",
      "Threshold decreased to 0.0183887779712677\n",
      "Iteration 35/200Joint iter 1/1, loss: 2.3048, abs_loss: 0.2790, ssl_loss: 2.0257\n",
      "\n",
      "Improve ppl percentage (train): 10.9819\n",
      "per-sample abstraction switch ratio: 0.1481 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 6, ratio: 0.2500\n",
      " - average advantage over greedy choice: 0.0686\n",
      "Threshold increased to 0.019574211910367012\n",
      "Iteration 36/200Joint iter 1/1, loss: 2.3837, abs_loss: 0.2889, ssl_loss: 2.0948\n",
      "\n",
      "Improve ppl percentage (train): 8.3276\n",
      "per-sample abstraction switch ratio: 0.2500 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 3, ratio: 0.1071\n",
      " - average advantage over greedy choice: 0.0733\n",
      "Threshold decreased to 0.015704408288002014\n",
      "Iteration 37/200Joint iter 1/1, loss: 2.2215, abs_loss: 0.1981, ssl_loss: 2.0234\n",
      "\n",
      "Improve ppl percentage (train): 12.3343\n",
      "per-sample abstraction switch ratio: 0.1071 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0357\n",
      " - average advantage over greedy choice: 0.0527\n",
      "Threshold decreased to 0.011065375059843063\n",
      "Iteration 38/200Joint iter 1/1, loss: 2.1406, abs_loss: 0.1377, ssl_loss: 2.0030\n",
      "\n",
      "Improve ppl percentage (train): 12.0960\n",
      "per-sample abstraction switch ratio: 0.0357 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 3, ratio: 0.1154\n",
      " - average advantage over greedy choice: 0.0612\n",
      "Threshold decreased to 0.008076610043644905\n",
      "Iteration 39/200Joint iter 1/1, loss: 2.2954, abs_loss: 0.2546, ssl_loss: 2.0409\n",
      "\n",
      "Improve ppl percentage (train): 12.4568\n",
      "per-sample abstraction switch ratio: 0.1154 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1538\n",
      " - average advantage over greedy choice: 0.0500\n",
      "Threshold decreased to 0.002343669068068266\n",
      "Iteration 40/200Joint iter 1/1, loss: 2.2500, abs_loss: 0.2278, ssl_loss: 2.0222\n",
      "\n",
      "Improve ppl percentage (train): 10.0429\n",
      "per-sample abstraction switch ratio: 0.1538 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0800\n",
      " - average advantage over greedy choice: 0.0498\n",
      "Threshold decreased to 0.0\n",
      "Iteration 41/200Joint iter 1/1, loss: 2.2805, abs_loss: 0.2144, ssl_loss: 2.0661\n",
      "\n",
      "Improve ppl percentage (train): 7.0916\n",
      "per-sample abstraction switch ratio: 0.0800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 11, ratio: 0.4231\n",
      " - average advantage over greedy choice: 0.0109\n",
      "Threshold increased to 0.0121223833411932\n",
      "Iteration 42/200Joint iter 1/1, loss: 2.3830, abs_loss: 0.3860, ssl_loss: 1.9971\n",
      "\n",
      "Improve ppl percentage (train): 10.8363\n",
      "per-sample abstraction switch ratio: 0.4231 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0769\n",
      " - average advantage over greedy choice: 0.0679\n",
      "Threshold decreased to 0.007042549550533295\n",
      "Iteration 43/200Joint iter 1/1, loss: 2.1545, abs_loss: 0.1947, ssl_loss: 1.9598\n",
      "\n",
      "Improve ppl percentage (train): 12.6861\n",
      "per-sample abstraction switch ratio: 0.0769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0370\n",
      " - average advantage over greedy choice: 0.0450\n",
      "Threshold decreased to 0.005278384312987328\n",
      "Iteration 44/200Joint iter 1/1, loss: 2.0779, abs_loss: 0.1378, ssl_loss: 1.9401\n",
      "\n",
      "Improve ppl percentage (train): 9.3777\n",
      "per-sample abstraction switch ratio: 0.0370 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.2000\n",
      " - average advantage over greedy choice: 0.0384\n",
      "Iteration 45/200Joint iter 1/1, loss: 2.2456, abs_loss: 0.2575, ssl_loss: 1.9881\n",
      "\n",
      "Improve ppl percentage (train): 7.7295\n",
      "per-sample abstraction switch ratio: 0.2000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.1923\n",
      " - average advantage over greedy choice: 0.0252\n",
      "Threshold decreased to 0.0024647144600749016\n",
      "Iteration 46/200Joint iter 1/1, loss: 2.1705, abs_loss: 0.2364, ssl_loss: 1.9341\n",
      "\n",
      "Improve ppl percentage (train): 9.7756\n",
      "per-sample abstraction switch ratio: 0.1923 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0417\n",
      " - average advantage over greedy choice: 0.0029\n",
      "Threshold decreased to 0.0007647601887583733\n",
      "Iteration 47/200Joint iter 1/1, loss: 2.1366, abs_loss: 0.1432, ssl_loss: 1.9934\n",
      "\n",
      "Improve ppl percentage (train): 9.6243\n",
      "per-sample abstraction switch ratio: 0.0417 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0714\n",
      " - average advantage over greedy choice: 0.0727\n",
      "Threshold decreased to 0.0\n",
      "Iteration 48/200Joint iter 1/1, loss: 1.9951, abs_loss: 0.1273, ssl_loss: 1.8677\n",
      "\n",
      "Improve ppl percentage (train): 14.1697\n",
      "per-sample abstraction switch ratio: 0.0714 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 18, ratio: 0.6667\n",
      " - average advantage over greedy choice: 0.0028\n",
      "Threshold increased to 0.008740117773413658\n",
      "Iteration 49/200Joint iter 1/1, loss: 2.0938, abs_loss: 0.1974, ssl_loss: 1.8965\n",
      "\n",
      "Improve ppl percentage (train): 11.5891\n",
      "per-sample abstraction switch ratio: 0.6667 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0568\n",
      "Threshold decreased to 0.0063811494037508965\n",
      "Iteration 50/200Joint iter 1/1, loss: 2.0247, abs_loss: 0.1325, ssl_loss: 1.8922\n",
      "\n",
      "Improve ppl percentage (train): 12.8241\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0741\n",
      " - average advantage over greedy choice: 0.0649\n",
      "Threshold decreased to 0.0\n",
      "Iteration 51/200Joint iter 1/1, loss: 2.0079, abs_loss: 0.1525, ssl_loss: 1.8554\n",
      "\n",
      "Improve ppl percentage (train): 16.2792\n",
      "per-sample abstraction switch ratio: 0.0741 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 12, ratio: 0.4286\n",
      " - average advantage over greedy choice: 0.0002\n",
      "Threshold increased to 0.00024847983149811625\n",
      "Iteration 52/200Joint iter 1/1, loss: 2.0317, abs_loss: 0.2182, ssl_loss: 1.8135\n",
      "\n",
      "Improve ppl percentage (train): 16.0367\n",
      "per-sample abstraction switch ratio: 0.4286 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 3, ratio: 0.1200\n",
      " - average advantage over greedy choice: 0.0074\n",
      "Threshold decreased to 0.0\n",
      "Iteration 53/200Joint iter 1/1, loss: 2.0894, abs_loss: 0.2189, ssl_loss: 1.8706\n",
      "\n",
      "Improve ppl percentage (train): 16.0630\n",
      "per-sample abstraction switch ratio: 0.1200 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 12, ratio: 0.4800\n",
      " - average advantage over greedy choice: 0.0002\n",
      "Threshold increased to 0.00039683817885816097\n",
      "Iteration 54/200Joint iter 1/1, loss: 2.0477, abs_loss: 0.1635, ssl_loss: 1.8842\n",
      "\n",
      "Improve ppl percentage (train): 13.9520\n",
      "per-sample abstraction switch ratio: 0.4800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0400\n",
      " - average advantage over greedy choice: 0.0242\n",
      "Threshold decreased to 0.0\n",
      "Iteration 55/200Joint iter 1/1, loss: 1.9261, abs_loss: 0.1056, ssl_loss: 1.8205\n",
      "\n",
      "Improve ppl percentage (train): 15.6153\n",
      "per-sample abstraction switch ratio: 0.0400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.6400\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 6.435155228246003e-05\n",
      "Iteration 56/200Joint iter 1/1, loss: 2.0511, abs_loss: 0.2253, ssl_loss: 1.8257\n",
      "\n",
      "Improve ppl percentage (train): 18.6222\n",
      "per-sample abstraction switch ratio: 0.6400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.1724\n",
      " - average advantage over greedy choice: 0.0093\n",
      "Threshold decreased to 0.0\n",
      "Iteration 57/200Joint iter 1/1, loss: 1.9716, abs_loss: 0.2598, ssl_loss: 1.7118\n",
      "\n",
      "Improve ppl percentage (train): 20.5875\n",
      "per-sample abstraction switch ratio: 0.1724 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 10, ratio: 0.3846\n",
      " - average advantage over greedy choice: 0.0123\n",
      "Threshold increased to 0.010279619134962559\n",
      "Iteration 58/200Joint iter 1/1, loss: 1.8375, abs_loss: 0.1117, ssl_loss: 1.7258\n",
      "\n",
      "Improve ppl percentage (train): 15.2871\n",
      "per-sample abstraction switch ratio: 0.3846 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 9, ratio: 0.3462\n",
      " - average advantage over greedy choice: 0.0739\n",
      "Threshold increased to 0.01889372617006302\n",
      "Iteration 59/200Joint iter 1/1, loss: 2.1104, abs_loss: 0.3438, ssl_loss: 1.7666\n",
      "\n",
      "Improve ppl percentage (train): 15.1889\n",
      "per-sample abstraction switch ratio: 0.3462 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0769\n",
      " - average advantage over greedy choice: 0.0528\n",
      "Threshold decreased to 0.012266196310520172\n",
      "Iteration 60/200Joint iter 1/1, loss: 1.9463, abs_loss: 0.1980, ssl_loss: 1.7483\n",
      "\n",
      "Improve ppl percentage (train): 14.1781\n",
      "per-sample abstraction switch ratio: 0.0769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0357\n",
      " - average advantage over greedy choice: 0.0400\n",
      "Threshold decreased to 0.008418545126914978\n",
      "Iteration 61/200Joint iter 1/1, loss: 1.8344, abs_loss: 0.1232, ssl_loss: 1.7112\n",
      "\n",
      "Improve ppl percentage (train): 17.0977\n",
      "per-sample abstraction switch ratio: 0.0357 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0113\n",
      "Threshold decreased to 0.002878874074667692\n",
      "Iteration 62/200Joint iter 1/1, loss: 1.8181, abs_loss: 0.1080, ssl_loss: 1.7101\n",
      "\n",
      "Improve ppl percentage (train): 18.0498\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0769\n",
      " - average advantage over greedy choice: 0.0055\n",
      "Threshold decreased to 0.001306526130065322\n",
      "Iteration 63/200Joint iter 1/1, loss: 1.8519, abs_loss: 0.1125, ssl_loss: 1.7394\n",
      "\n",
      "Improve ppl percentage (train): 13.7646\n",
      "per-sample abstraction switch ratio: 0.0769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0400\n",
      " - average advantage over greedy choice: 0.0017\n",
      "Threshold decreased to 0.0004347078502178192\n",
      "Iteration 64/200Joint iter 1/1, loss: 1.8846, abs_loss: 0.1234, ssl_loss: 1.7612\n",
      "\n",
      "Improve ppl percentage (train): 17.5884\n",
      "per-sample abstraction switch ratio: 0.0400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0769\n",
      " - average advantage over greedy choice: 0.0037\n",
      "Threshold decreased to 9.88817191682756e-06\n",
      "Iteration 65/200Joint iter 1/1, loss: 1.8632, abs_loss: 0.1383, ssl_loss: 1.7249\n",
      "\n",
      "Improve ppl percentage (train): 17.0961\n",
      "per-sample abstraction switch ratio: 0.0769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0741\n",
      " - average advantage over greedy choice: 0.0181\n",
      "Threshold decreased to 0.0\n",
      "Iteration 66/200Joint iter 1/1, loss: 1.8071, abs_loss: 0.1412, ssl_loss: 1.6659\n",
      "\n",
      "Improve ppl percentage (train): 19.6238\n",
      "per-sample abstraction switch ratio: 0.0741 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 12, ratio: 0.4615\n",
      " - average advantage over greedy choice: 0.0003\n",
      "Threshold increased to 0.0005535006639547646\n",
      "Iteration 67/200Joint iter 1/1, loss: 1.7906, abs_loss: 0.0920, ssl_loss: 1.6986\n",
      "\n",
      "Improve ppl percentage (train): 15.0524\n",
      "per-sample abstraction switch ratio: 0.4615 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 3, ratio: 0.1111\n",
      " - average advantage over greedy choice: 0.0076\n",
      "Threshold decreased to 0.0\n",
      "Iteration 68/200Joint iter 1/1, loss: 1.8698, abs_loss: 0.1838, ssl_loss: 1.6860\n",
      "\n",
      "Improve ppl percentage (train): 17.2179\n",
      "per-sample abstraction switch ratio: 0.1111 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 12, ratio: 0.4615\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 1.7166136956348055e-07\n",
      "Iteration 69/200Joint iter 1/1, loss: 1.7259, abs_loss: 0.0500, ssl_loss: 1.6759\n",
      "\n",
      "Improve ppl percentage (train): 16.7815\n",
      "per-sample abstraction switch ratio: 0.4615 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 14, ratio: 0.5600\n",
      " - average advantage over greedy choice: 0.0009\n",
      "Threshold increased to 0.0012841729912906885\n",
      "Iteration 70/200Joint iter 1/1, loss: 1.8457, abs_loss: 0.1444, ssl_loss: 1.7013\n",
      "\n",
      "Improve ppl percentage (train): 16.2731\n",
      "per-sample abstraction switch ratio: 0.5600 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.00012841727584600449\n",
      "Iteration 71/200Joint iter 1/1, loss: 1.7902, abs_loss: 0.0464, ssl_loss: 1.7438\n",
      "\n",
      "Improve ppl percentage (train): 20.3458\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1538\n",
      " - average advantage over greedy choice: 0.0106\n",
      "Threshold decreased to 0.0\n",
      "Iteration 72/200Joint iter 1/1, loss: 1.8854, abs_loss: 0.2106, ssl_loss: 1.6748\n",
      "\n",
      "Improve ppl percentage (train): 19.3231\n",
      "per-sample abstraction switch ratio: 0.1538 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.6154\n",
      " - average advantage over greedy choice: 0.0019\n",
      "Threshold increased to 0.0026518034283071756\n",
      "Iteration 73/200Joint iter 1/1, loss: 1.8683, abs_loss: 0.1877, ssl_loss: 1.6806\n",
      "\n",
      "Improve ppl percentage (train): 19.3493\n",
      "per-sample abstraction switch ratio: 0.6154 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 3, ratio: 0.1154\n",
      " - average advantage over greedy choice: 0.0112\n",
      "Threshold decreased to 0.0019169573206454515\n",
      "Iteration 74/200Joint iter 1/1, loss: 1.8224, abs_loss: 0.1378, ssl_loss: 1.6846\n",
      "\n",
      "Improve ppl percentage (train): 18.6098\n",
      "per-sample abstraction switch ratio: 0.1154 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1600\n",
      " - average advantage over greedy choice: 0.0351\n",
      "Threshold decreased to 0.0\n",
      "Iteration 75/200Joint iter 1/1, loss: 1.9484, abs_loss: 0.2416, ssl_loss: 1.7068\n",
      "\n",
      "Improve ppl percentage (train): 17.4183\n",
      "per-sample abstraction switch ratio: 0.1600 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 15, ratio: 0.6000\n",
      " - average advantage over greedy choice: 0.0010\n",
      "Threshold increased to 0.0010909080738201737\n",
      "Iteration 76/200Joint iter 1/1, loss: 1.9202, abs_loss: 0.2287, ssl_loss: 1.6915\n",
      "\n",
      "Improve ppl percentage (train): 17.6508\n",
      "per-sample abstraction switch ratio: 0.6000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0370\n",
      " - average advantage over greedy choice: 0.0015\n",
      "Threshold decreased to 0.00037786964094266295\n",
      "Iteration 77/200Joint iter 1/1, loss: 1.7675, abs_loss: 0.1027, ssl_loss: 1.6648\n",
      "\n",
      "Improve ppl percentage (train): 20.4876\n",
      "per-sample abstraction switch ratio: 0.0370 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0010\n",
      "Threshold decreased to 0.00021642209321726114\n",
      "Iteration 78/200Joint iter 1/1, loss: 1.7525, abs_loss: 0.0825, ssl_loss: 1.6700\n",
      "\n",
      "Improve ppl percentage (train): 17.3455\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0714\n",
      " - average advantage over greedy choice: 0.0048\n",
      "Threshold decreased to 0.0\n",
      "Iteration 79/200Joint iter 1/1, loss: 1.7174, abs_loss: 0.1346, ssl_loss: 1.5828\n",
      "\n",
      "Improve ppl percentage (train): 24.5448\n",
      "per-sample abstraction switch ratio: 0.0714 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 13, ratio: 0.5200\n",
      " - average advantage over greedy choice: 0.0001\n",
      "Threshold increased to 0.0003160714986734092\n",
      "Iteration 80/200Joint iter 1/1, loss: 1.7587, abs_loss: 0.0979, ssl_loss: 1.6609\n",
      "\n",
      "Improve ppl percentage (train): 15.9423\n",
      "per-sample abstraction switch ratio: 0.5200 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0400\n",
      " - average advantage over greedy choice: 0.0030\n",
      "Threshold decreased to 6.179808406159282e-05\n",
      "Iteration 81/200Joint iter 1/1, loss: 1.8013, abs_loss: 0.0975, ssl_loss: 1.7038\n",
      "\n",
      "Improve ppl percentage (train): 17.1378\n",
      "per-sample abstraction switch ratio: 0.0400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0741\n",
      " - average advantage over greedy choice: 0.0014\n",
      "Threshold decreased to 0.0\n",
      "Iteration 82/200Joint iter 1/1, loss: 1.7604, abs_loss: 0.1476, ssl_loss: 1.6128\n",
      "\n",
      "Improve ppl percentage (train): 20.8664\n",
      "per-sample abstraction switch ratio: 0.0741 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 19, ratio: 0.7308\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.574920756615029e-07\n",
      "Iteration 83/200Joint iter 1/1, loss: 1.6696, abs_loss: 0.0474, ssl_loss: 1.6222\n",
      "\n",
      "Improve ppl percentage (train): 21.0664\n",
      "per-sample abstraction switch ratio: 0.7308 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 13, ratio: 0.5000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.83241291754166e-07\n",
      "Iteration 84/200Joint iter 1/1, loss: 1.6543, abs_loss: 0.0445, ssl_loss: 1.6097\n",
      "\n",
      "Improve ppl percentage (train): 20.7949\n",
      "per-sample abstraction switch ratio: 0.5000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 19, ratio: 0.7308\n",
      " - average advantage over greedy choice: 0.0005\n",
      "Threshold increased to 0.0018049618229269981\n",
      "Iteration 85/200Joint iter 1/1, loss: 1.7017, abs_loss: 0.1012, ssl_loss: 1.6006\n",
      "\n",
      "Improve ppl percentage (train): 16.9367\n",
      "per-sample abstraction switch ratio: 0.7308 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0800\n",
      " - average advantage over greedy choice: 0.0140\n",
      "Threshold decreased to 0.0004629472969099879\n",
      "Iteration 86/200Joint iter 1/1, loss: 1.7894, abs_loss: 0.1726, ssl_loss: 1.6168\n",
      "\n",
      "Improve ppl percentage (train): 18.9842\n",
      "per-sample abstraction switch ratio: 0.0800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 4.6294735511764884e-05\n",
      "Iteration 87/200Joint iter 1/1, loss: 1.6704, abs_loss: 0.0322, ssl_loss: 1.6382\n",
      "\n",
      "Improve ppl percentage (train): 18.7751\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0417\n",
      " - average advantage over greedy choice: 0.0022\n",
      "Threshold decreased to 0.0\n",
      "Iteration 88/200Joint iter 1/1, loss: 1.7560, abs_loss: 0.0865, ssl_loss: 1.6695\n",
      "\n",
      "Improve ppl percentage (train): 12.4545\n",
      "per-sample abstraction switch ratio: 0.0417 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.6154\n",
      " - average advantage over greedy choice: 0.0025\n",
      "Threshold increased to 0.00497873779386282\n",
      "Iteration 89/200Joint iter 1/1, loss: 1.7160, abs_loss: 0.1261, ssl_loss: 1.5899\n",
      "\n",
      "Improve ppl percentage (train): 18.8094\n",
      "per-sample abstraction switch ratio: 0.6154 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.0004978738725185394\n",
      "Iteration 90/200Joint iter 1/1, loss: 1.5262, abs_loss: 0.0356, ssl_loss: 1.4907\n",
      "\n",
      "Improve ppl percentage (train): 20.5540\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0357\n",
      " - average advantage over greedy choice: 0.0051\n",
      "Threshold decreased to 3.2936426578089595e-05\n",
      "Iteration 91/200Joint iter 1/1, loss: 1.6195, abs_loss: 0.0914, ssl_loss: 1.5281\n",
      "\n",
      "Improve ppl percentage (train): 22.3314\n",
      "per-sample abstraction switch ratio: 0.0357 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 3.2936441130004823e-06\n",
      "Iteration 92/200Joint iter 1/1, loss: 1.6319, abs_loss: 0.0280, ssl_loss: 1.6039\n",
      "\n",
      "Improve ppl percentage (train): 13.9933\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0400\n",
      " - average advantage over greedy choice: 0.0148\n",
      "Threshold decreased to 0.0\n",
      "Iteration 93/200Joint iter 1/1, loss: 1.7096, abs_loss: 0.0832, ssl_loss: 1.6264\n",
      "\n",
      "Improve ppl percentage (train): 13.0768\n",
      "per-sample abstraction switch ratio: 0.0400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.6154\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 1.9311904964069981e-07\n",
      "Iteration 94/200Joint iter 1/1, loss: 1.5811, abs_loss: 0.0332, ssl_loss: 1.5479\n",
      "\n",
      "Improve ppl percentage (train): 15.6207\n",
      "per-sample abstraction switch ratio: 0.6154 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 18, ratio: 0.6667\n",
      " - average advantage over greedy choice: 0.0003\n",
      "Threshold increased to 0.000894289230927825\n",
      "Iteration 95/200Joint iter 1/1, loss: 1.6802, abs_loss: 0.1475, ssl_loss: 1.5327\n",
      "\n",
      "Improve ppl percentage (train): 19.1006\n",
      "per-sample abstraction switch ratio: 0.6667 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0804\n",
      "Threshold decreased to 0.0\n",
      "Iteration 96/200Joint iter 1/1, loss: 1.6356, abs_loss: 0.0891, ssl_loss: 1.5465\n",
      "\n",
      "Improve ppl percentage (train): 22.6509\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 17, ratio: 0.6538\n",
      " - average advantage over greedy choice: 0.0006\n",
      "Threshold increased to 0.0019306110916659236\n",
      "Iteration 97/200Joint iter 1/1, loss: 1.6719, abs_loss: 0.0889, ssl_loss: 1.5830\n",
      "\n",
      "Improve ppl percentage (train): 20.2351\n",
      "per-sample abstraction switch ratio: 0.6538 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0065\n",
      "Threshold decreased to 0.0013662592973560095\n",
      "Iteration 98/200Joint iter 1/1, loss: 1.6431, abs_loss: 0.0839, ssl_loss: 1.5592\n",
      "\n",
      "Improve ppl percentage (train): 21.3198\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.00013662595301866531\n",
      "Iteration 99/200Joint iter 1/1, loss: 1.5547, abs_loss: 0.0273, ssl_loss: 1.5274\n",
      "\n",
      "Improve ppl percentage (train): 19.2898\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 1.3662604033015668e-05\n",
      "Iteration 100/200Joint iter 1/1, loss: 1.4850, abs_loss: 0.0282, ssl_loss: 1.4568\n",
      "\n",
      "Improve ppl percentage (train): 24.3639\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 1.3662611308973283e-06\n",
      "Iteration 101/200Joint iter 1/1, loss: 1.5695, abs_loss: 0.0262, ssl_loss: 1.5432\n",
      "\n",
      "Improve ppl percentage (train): 19.6664\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 1.3662611308973283e-07\n",
      "Iteration 102/200Joint iter 1/1, loss: 1.4956, abs_loss: 0.0254, ssl_loss: 1.4702\n",
      "\n",
      "Improve ppl percentage (train): 19.7647\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 18, ratio: 0.6667\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.5698536748896004e-07\n",
      "Iteration 103/200Joint iter 1/1, loss: 1.5585, abs_loss: 0.0236, ssl_loss: 1.5350\n",
      "\n",
      "Improve ppl percentage (train): 15.7188\n",
      "per-sample abstraction switch ratio: 0.6667 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 17, ratio: 0.6071\n",
      " - average advantage over greedy choice: 0.0009\n",
      "Threshold increased to 0.0026601648423820734\n",
      "Iteration 104/200Joint iter 1/1, loss: 1.5265, abs_loss: 0.0875, ssl_loss: 1.4390\n",
      "\n",
      "Improve ppl percentage (train): 19.6751\n",
      "per-sample abstraction switch ratio: 0.6071 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.000266016460955143\n",
      "Iteration 105/200Joint iter 1/1, loss: 1.5717, abs_loss: 0.0254, ssl_loss: 1.5463\n",
      "\n",
      "Improve ppl percentage (train): 21.0074\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 2.660165773704648e-05\n",
      "Iteration 106/200Joint iter 1/1, loss: 1.5749, abs_loss: 0.0246, ssl_loss: 1.5504\n",
      "\n",
      "Improve ppl percentage (train): 23.8169\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0800\n",
      " - average advantage over greedy choice: 0.0017\n",
      "Threshold decreased to 0.0\n",
      "Iteration 107/200Joint iter 1/1, loss: 1.7072, abs_loss: 0.1500, ssl_loss: 1.5572\n",
      "\n",
      "Improve ppl percentage (train): 16.5366\n",
      "per-sample abstraction switch ratio: 0.0800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 13, ratio: 0.4643\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 1.7166136956348055e-07\n",
      "Iteration 108/200Joint iter 1/1, loss: 1.5258, abs_loss: 0.0244, ssl_loss: 1.5015\n",
      "\n",
      "Improve ppl percentage (train): 22.6326\n",
      "per-sample abstraction switch ratio: 0.4643 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.6154\n",
      " - average advantage over greedy choice: 0.0013\n",
      "Threshold increased to 0.003725240472704172\n",
      "Iteration 109/200Joint iter 1/1, loss: 1.6184, abs_loss: 0.0891, ssl_loss: 1.5293\n",
      "\n",
      "Improve ppl percentage (train): 19.0144\n",
      "per-sample abstraction switch ratio: 0.6154 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.0003725241404026747\n",
      "Iteration 110/200Joint iter 1/1, loss: 1.5202, abs_loss: 0.0198, ssl_loss: 1.5004\n",
      "\n",
      "Improve ppl percentage (train): 21.9309\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 3.725243732333183e-05\n",
      "Iteration 111/200Joint iter 1/1, loss: 1.5190, abs_loss: 0.0188, ssl_loss: 1.5002\n",
      "\n",
      "Improve ppl percentage (train): 22.3086\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 3.725243004737422e-06\n",
      "Iteration 112/200Joint iter 1/1, loss: 1.5881, abs_loss: 0.0191, ssl_loss: 1.5690\n",
      "\n",
      "Improve ppl percentage (train): 20.7595\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0769\n",
      " - average advantage over greedy choice: 0.0246\n",
      "Threshold decreased to 0.0\n",
      "Iteration 113/200Joint iter 1/1, loss: 1.6826, abs_loss: 0.1485, ssl_loss: 1.5341\n",
      "\n",
      "Improve ppl percentage (train): 22.9242\n",
      "per-sample abstraction switch ratio: 0.0769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 21, ratio: 0.8077\n",
      " - average advantage over greedy choice: 0.0045\n",
      "Threshold increased to 0.007210850715637207\n",
      "Iteration 114/200Joint iter 1/1, loss: 1.8251, abs_loss: 0.2677, ssl_loss: 1.5574\n",
      "\n",
      "Improve ppl percentage (train): 22.5078\n",
      "per-sample abstraction switch ratio: 0.8077 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0400\n",
      " - average advantage over greedy choice: 0.0301\n",
      "Threshold decreased to 0.006139490753412247\n",
      "Iteration 115/200Joint iter 1/1, loss: 1.6563, abs_loss: 0.0905, ssl_loss: 1.5659\n",
      "\n",
      "Improve ppl percentage (train): 17.8648\n",
      "per-sample abstraction switch ratio: 0.0400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.0006139492616057396\n",
      "Iteration 116/200Joint iter 1/1, loss: 1.5326, abs_loss: 0.0175, ssl_loss: 1.5151\n",
      "\n",
      "Improve ppl percentage (train): 25.6708\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0417\n",
      " - average advantage over greedy choice: 0.0100\n",
      "Threshold decreased to 0.0\n",
      "Iteration 117/200Joint iter 1/1, loss: 1.6440, abs_loss: 0.0840, ssl_loss: 1.5600\n",
      "\n",
      "Improve ppl percentage (train): 20.5642\n",
      "per-sample abstraction switch ratio: 0.0417 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 17, ratio: 0.6538\n",
      " - average advantage over greedy choice: 0.0016\n",
      "Threshold increased to 0.002449135761708021\n",
      "Iteration 118/200Joint iter 1/1, loss: 1.6821, abs_loss: 0.1462, ssl_loss: 1.5359\n",
      "\n",
      "Improve ppl percentage (train): 23.5096\n",
      "per-sample abstraction switch ratio: 0.6538 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0061\n",
      "Threshold decreased to 0.0013454132713377476\n",
      "Iteration 119/200Joint iter 1/1, loss: 1.6043, abs_loss: 0.0755, ssl_loss: 1.5287\n",
      "\n",
      "Improve ppl percentage (train): 18.4863\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.0001345413038507104\n",
      "Iteration 120/200Joint iter 1/1, loss: 1.5048, abs_loss: 0.0206, ssl_loss: 1.4842\n",
      "\n",
      "Improve ppl percentage (train): 21.0542\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 1.3454133295454085e-05\n",
      "Iteration 121/200Joint iter 1/1, loss: 1.5869, abs_loss: 0.0211, ssl_loss: 1.5659\n",
      "\n",
      "Improve ppl percentage (train): 18.7286\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0769\n",
      " - average advantage over greedy choice: 0.0078\n",
      "Threshold decreased to 0.0\n",
      "Iteration 122/200Joint iter 1/1, loss: 1.6493, abs_loss: 0.1298, ssl_loss: 1.5194\n",
      "\n",
      "Improve ppl percentage (train): 23.1446\n",
      "per-sample abstraction switch ratio: 0.0769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 18, ratio: 0.6667\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 1.7166136956348055e-07\n",
      "Iteration 123/200Joint iter 1/1, loss: 1.5244, abs_loss: 0.0211, ssl_loss: 1.5033\n",
      "\n",
      "Improve ppl percentage (train): 24.3076\n",
      "per-sample abstraction switch ratio: 0.6667 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 21, ratio: 0.8400\n",
      " - average advantage over greedy choice: 0.0028\n",
      "Threshold increased to 0.0084172822535038\n",
      "Iteration 124/200Joint iter 1/1, loss: 1.7827, abs_loss: 0.2340, ssl_loss: 1.5487\n",
      "\n",
      "Improve ppl percentage (train): 20.7572\n",
      "per-sample abstraction switch ratio: 0.8400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.0008417284116148949\n",
      "Iteration 125/200Joint iter 1/1, loss: 1.4734, abs_loss: 0.0232, ssl_loss: 1.4502\n",
      "\n",
      "Improve ppl percentage (train): 19.8574\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0400\n",
      " - average advantage over greedy choice: 0.0232\n",
      "Threshold decreased to 0.0\n",
      "Iteration 126/200Joint iter 1/1, loss: 1.6197, abs_loss: 0.0910, ssl_loss: 1.5287\n",
      "\n",
      "Improve ppl percentage (train): 21.0016\n",
      "per-sample abstraction switch ratio: 0.0400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 20, ratio: 0.7692\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.1457671550706436e-07\n",
      "Iteration 127/200Joint iter 1/1, loss: 1.5717, abs_loss: 0.0202, ssl_loss: 1.5515\n",
      "\n",
      "Improve ppl percentage (train): 22.0643\n",
      "per-sample abstraction switch ratio: 0.7692 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 11, ratio: 0.4074\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.2186505904974183e-07\n",
      "Iteration 128/200Joint iter 1/1, loss: 1.4861, abs_loss: 0.0178, ssl_loss: 1.4683\n",
      "\n",
      "Improve ppl percentage (train): 23.4014\n",
      "per-sample abstraction switch ratio: 0.4074 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 13, ratio: 0.5000\n",
      " - average advantage over greedy choice: 0.0002\n",
      "Threshold increased to 0.000526303076185286\n",
      "Iteration 129/200Joint iter 1/1, loss: 1.6040, abs_loss: 0.0781, ssl_loss: 1.5259\n",
      "\n",
      "Improve ppl percentage (train): 24.7661\n",
      "per-sample abstraction switch ratio: 0.5000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 5.263031926006079e-05\n",
      "Iteration 130/200Joint iter 1/1, loss: 1.5689, abs_loss: 0.0158, ssl_loss: 1.5531\n",
      "\n",
      "Improve ppl percentage (train): 22.3433\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 5.263034836389124e-06\n",
      "Iteration 131/200Joint iter 1/1, loss: 1.4466, abs_loss: 0.0143, ssl_loss: 1.4323\n",
      "\n",
      "Improve ppl percentage (train): 24.1210\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0062\n",
      "Threshold decreased to 0.0\n",
      "Iteration 132/200Joint iter 1/1, loss: 1.5959, abs_loss: 0.0838, ssl_loss: 1.5121\n",
      "\n",
      "Improve ppl percentage (train): 22.2808\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.6154\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.1457671550706436e-07\n",
      "Iteration 133/200Joint iter 1/1, loss: 1.5188, abs_loss: 0.0133, ssl_loss: 1.5055\n",
      "\n",
      "Improve ppl percentage (train): 18.3553\n",
      "per-sample abstraction switch ratio: 0.6154 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 14, ratio: 0.5385\n",
      " - average advantage over greedy choice: 0.0008\n",
      "Threshold increased to 0.0021170140244066715\n",
      "Iteration 134/200Joint iter 1/1, loss: 1.6035, abs_loss: 0.0879, ssl_loss: 1.5156\n",
      "\n",
      "Improve ppl percentage (train): 21.3056\n",
      "per-sample abstraction switch ratio: 0.5385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.00021170149557292461\n",
      "Iteration 135/200Joint iter 1/1, loss: 1.5577, abs_loss: 0.0149, ssl_loss: 1.5428\n",
      "\n",
      "Improve ppl percentage (train): 19.7285\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 2.1170155378058553e-05\n",
      "Iteration 136/200Joint iter 1/1, loss: 1.5150, abs_loss: 0.0143, ssl_loss: 1.5007\n",
      "\n",
      "Improve ppl percentage (train): 24.8955\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 2.1170162654016167e-06\n",
      "Iteration 137/200Joint iter 1/1, loss: 1.5219, abs_loss: 0.0129, ssl_loss: 1.5090\n",
      "\n",
      "Improve ppl percentage (train): 24.1629\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 2.1170171748963185e-07\n",
      "Iteration 138/200Joint iter 1/1, loss: 1.4681, abs_loss: 0.0125, ssl_loss: 1.4556\n",
      "\n",
      "Improve ppl percentage (train): 27.6651\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 13, ratio: 0.4815\n",
      " - average advantage over greedy choice: 0.0017\n",
      "Threshold increased to 0.004057473503053188\n",
      "Iteration 139/200Joint iter 1/1, loss: 1.5622, abs_loss: 0.0723, ssl_loss: 1.4899\n",
      "\n",
      "Improve ppl percentage (train): 24.8223\n",
      "per-sample abstraction switch ratio: 0.4815 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.0004057474434375763\n",
      "Iteration 140/200Joint iter 1/1, loss: 1.5299, abs_loss: 0.0124, ssl_loss: 1.5175\n",
      "\n",
      "Improve ppl percentage (train): 23.4008\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 4.057475598528981e-05\n",
      "Iteration 141/200Joint iter 1/1, loss: 1.4710, abs_loss: 0.0122, ssl_loss: 1.4588\n",
      "\n",
      "Improve ppl percentage (train): 23.4278\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 4.0574777813162655e-06\n",
      "Iteration 142/200Joint iter 1/1, loss: 1.5634, abs_loss: 0.0113, ssl_loss: 1.5521\n",
      "\n",
      "Improve ppl percentage (train): 20.5209\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 4.057478690810967e-07\n",
      "Iteration 143/200Joint iter 1/1, loss: 1.4940, abs_loss: 0.0118, ssl_loss: 1.4821\n",
      "\n",
      "Improve ppl percentage (train): 23.3158\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 12, ratio: 0.4444\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 5.348865670384839e-07\n",
      "Iteration 144/200Joint iter 1/1, loss: 1.5131, abs_loss: 0.0113, ssl_loss: 1.5018\n",
      "\n",
      "Improve ppl percentage (train): 22.9551\n",
      "per-sample abstraction switch ratio: 0.4444 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 7, ratio: 0.2917\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 8.875384196471714e-07\n",
      "Iteration 145/200Joint iter 1/1, loss: 1.5839, abs_loss: 0.0106, ssl_loss: 1.5733\n",
      "\n",
      "Improve ppl percentage (train): 22.7968\n",
      "per-sample abstraction switch ratio: 0.2917 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 8.875383628037525e-08\n",
      "Iteration 146/200Joint iter 1/1, loss: 1.4726, abs_loss: 0.0115, ssl_loss: 1.4612\n",
      "\n",
      "Improve ppl percentage (train): 26.4668\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 17, ratio: 0.6800\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 1.3762141293227614e-07\n",
      "Iteration 147/200Joint iter 1/1, loss: 1.5451, abs_loss: 0.0103, ssl_loss: 1.5348\n",
      "\n",
      "Improve ppl percentage (train): 21.1211\n",
      "per-sample abstraction switch ratio: 0.6800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.5926\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.3562722023816605e-07\n",
      "Iteration 148/200Joint iter 1/1, loss: 1.4688, abs_loss: 0.0102, ssl_loss: 1.4587\n",
      "\n",
      "Improve ppl percentage (train): 23.2612\n",
      "per-sample abstraction switch ratio: 0.5926 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 13, ratio: 0.5000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 4.2311501147196395e-07\n",
      "Iteration 149/200Joint iter 1/1, loss: 1.5433, abs_loss: 0.0100, ssl_loss: 1.5333\n",
      "\n",
      "Improve ppl percentage (train): 22.6957\n",
      "per-sample abstraction switch ratio: 0.5000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0741\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 1.9251521621299617e-07\n",
      "Iteration 150/200Joint iter 1/1, loss: 1.5095, abs_loss: 0.0103, ssl_loss: 1.4992\n",
      "\n",
      "Improve ppl percentage (train): 26.9151\n",
      "per-sample abstraction switch ratio: 0.0741 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 14, ratio: 0.5385\n",
      " - average advantage over greedy choice: 0.0020\n",
      "Threshold increased to 0.005082526709884405\n",
      "Iteration 151/200Joint iter 1/1, loss: 1.5789, abs_loss: 0.0801, ssl_loss: 1.4988\n",
      "\n",
      "Improve ppl percentage (train): 19.7771\n",
      "per-sample abstraction switch ratio: 0.5385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.0005082529969513416\n",
      "Iteration 152/200Joint iter 1/1, loss: 1.4895, abs_loss: 0.0102, ssl_loss: 1.4792\n",
      "\n",
      "Improve ppl percentage (train): 25.9609\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 5.082529969513416e-05\n",
      "Iteration 153/200Joint iter 1/1, loss: 1.5305, abs_loss: 0.0096, ssl_loss: 1.5209\n",
      "\n",
      "Improve ppl percentage (train): 24.0633\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0141\n",
      "Threshold decreased to 0.0\n",
      "Iteration 154/200Joint iter 1/1, loss: 1.5974, abs_loss: 0.0817, ssl_loss: 1.5157\n",
      "\n",
      "Improve ppl percentage (train): 21.2214\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 17, ratio: 0.6296\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.574920756615029e-07\n",
      "Iteration 155/200Joint iter 1/1, loss: 1.4813, abs_loss: 0.0100, ssl_loss: 1.4713\n",
      "\n",
      "Improve ppl percentage (train): 29.5108\n",
      "per-sample abstraction switch ratio: 0.6296 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 12, ratio: 0.4800\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.175735514560074e-07\n",
      "Iteration 156/200Joint iter 1/1, loss: 1.5393, abs_loss: 0.0105, ssl_loss: 1.5288\n",
      "\n",
      "Improve ppl percentage (train): 23.9127\n",
      "per-sample abstraction switch ratio: 0.4800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.5926\n",
      " - average advantage over greedy choice: 0.0012\n",
      "Threshold increased to 0.0033227738458663225\n",
      "Iteration 157/200Joint iter 1/1, loss: 1.5641, abs_loss: 0.0844, ssl_loss: 1.4796\n",
      "\n",
      "Improve ppl percentage (train): 23.9002\n",
      "per-sample abstraction switch ratio: 0.5926 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 2, ratio: 0.0769\n",
      " - average advantage over greedy choice: 0.0213\n",
      "Threshold decreased to 0.0017107928870245814\n",
      "Iteration 158/200Joint iter 1/1, loss: 1.6392, abs_loss: 0.1592, ssl_loss: 1.4800\n",
      "\n",
      "Improve ppl percentage (train): 25.1591\n",
      "per-sample abstraction switch ratio: 0.0769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.00017107930034399033\n",
      "Iteration 159/200Joint iter 1/1, loss: 1.5526, abs_loss: 0.0094, ssl_loss: 1.5432\n",
      "\n",
      "Improve ppl percentage (train): 18.1982\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 1.7107930034399033e-05\n",
      "Iteration 160/200Joint iter 1/1, loss: 1.5222, abs_loss: 0.0101, ssl_loss: 1.5121\n",
      "\n",
      "Improve ppl percentage (train): 22.3696\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 1.7107940948335454e-06\n",
      "Iteration 161/200Joint iter 1/1, loss: 1.4784, abs_loss: 0.0101, ssl_loss: 1.4683\n",
      "\n",
      "Improve ppl percentage (train): 21.0011\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 1.7107947769545717e-07\n",
      "Iteration 162/200Joint iter 1/1, loss: 1.4818, abs_loss: 0.0103, ssl_loss: 1.4715\n",
      "\n",
      "Improve ppl percentage (train): 22.1464\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 14, ratio: 0.5185\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.531423319851456e-07\n",
      "Iteration 163/200Joint iter 1/1, loss: 1.4540, abs_loss: 0.0101, ssl_loss: 1.4439\n",
      "\n",
      "Improve ppl percentage (train): 24.5381\n",
      "per-sample abstraction switch ratio: 0.5185 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.5714\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.093090583661251e-07\n",
      "Iteration 164/200Joint iter 1/1, loss: 1.4693, abs_loss: 0.0094, ssl_loss: 1.4600\n",
      "\n",
      "Improve ppl percentage (train): 25.8595\n",
      "per-sample abstraction switch ratio: 0.5714 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 17, ratio: 0.6538\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.5165280110049935e-07\n",
      "Iteration 165/200Joint iter 1/1, loss: 1.5292, abs_loss: 0.0098, ssl_loss: 1.5194\n",
      "\n",
      "Improve ppl percentage (train): 24.9673\n",
      "per-sample abstraction switch ratio: 0.6538 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 11, ratio: 0.3929\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.891905748787394e-07\n",
      "Iteration 166/200Joint iter 1/1, loss: 1.4543, abs_loss: 0.0092, ssl_loss: 1.4452\n",
      "\n",
      "Improve ppl percentage (train): 26.1297\n",
      "per-sample abstraction switch ratio: 0.3929 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 9, ratio: 0.3600\n",
      " - average advantage over greedy choice: 0.0016\n",
      "Threshold increased to 0.002655361546203494\n",
      "Iteration 167/200Joint iter 1/1, loss: 1.5984, abs_loss: 0.0852, ssl_loss: 1.5132\n",
      "\n",
      "Improve ppl percentage (train): 23.8714\n",
      "per-sample abstraction switch ratio: 0.3600 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0400\n",
      " - average advantage over greedy choice: 0.0296\n",
      "Threshold decreased to 0.0\n",
      "Iteration 168/200Joint iter 1/1, loss: 1.6287, abs_loss: 0.0846, ssl_loss: 1.5441\n",
      "\n",
      "Improve ppl percentage (train): 23.4326\n",
      "per-sample abstraction switch ratio: 0.0400 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 15, ratio: 0.5556\n",
      " - average advantage over greedy choice: 0.0018\n",
      "Threshold increased to 0.0024494791869074106\n",
      "Iteration 169/200Joint iter 1/1, loss: 1.6123, abs_loss: 0.1425, ssl_loss: 1.4698\n",
      "\n",
      "Improve ppl percentage (train): 20.5097\n",
      "per-sample abstraction switch ratio: 0.5556 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.0002449480816721916\n",
      "Iteration 170/200Joint iter 1/1, loss: 1.5058, abs_loss: 0.0091, ssl_loss: 1.4967\n",
      "\n",
      "Improve ppl percentage (train): 24.7410\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 2.44948168983683e-05\n",
      "Iteration 171/200Joint iter 1/1, loss: 1.4986, abs_loss: 0.0101, ssl_loss: 1.4885\n",
      "\n",
      "Improve ppl percentage (train): 27.1624\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 2.4494820536347106e-06\n",
      "Iteration 172/200Joint iter 1/1, loss: 1.5444, abs_loss: 0.0097, ssl_loss: 1.5347\n",
      "\n",
      "Improve ppl percentage (train): 21.1549\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 2.4494829631294124e-07\n",
      "Iteration 173/200Joint iter 1/1, loss: 1.5061, abs_loss: 0.0093, ssl_loss: 1.4968\n",
      "\n",
      "Improve ppl percentage (train): 22.1737\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 17, ratio: 0.6800\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.8198689960845513e-07\n",
      "Iteration 174/200Joint iter 1/1, loss: 1.5655, abs_loss: 0.0089, ssl_loss: 1.5565\n",
      "\n",
      "Improve ppl percentage (train): 22.0331\n",
      "per-sample abstraction switch ratio: 0.6800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 13, ratio: 0.4483\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.426560510888521e-07\n",
      "Iteration 175/200Joint iter 1/1, loss: 1.4261, abs_loss: 0.0092, ssl_loss: 1.4170\n",
      "\n",
      "Improve ppl percentage (train): 30.0614\n",
      "per-sample abstraction switch ratio: 0.4483 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 8, ratio: 0.3200\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 4.3646977587741276e-07\n",
      "Iteration 176/200Joint iter 1/1, loss: 1.5466, abs_loss: 0.0089, ssl_loss: 1.5377\n",
      "\n",
      "Improve ppl percentage (train): 21.6131\n",
      "per-sample abstraction switch ratio: 0.3200 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 10, ratio: 0.3846\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 5.288851525619975e-07\n",
      "Iteration 177/200Joint iter 1/1, loss: 1.5171, abs_loss: 0.0077, ssl_loss: 1.5094\n",
      "\n",
      "Improve ppl percentage (train): 20.8927\n",
      "per-sample abstraction switch ratio: 0.3846 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 7, ratio: 0.2593\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 8.117626748571638e-07\n",
      "Iteration 178/200Joint iter 1/1, loss: 1.4840, abs_loss: 0.0086, ssl_loss: 1.4754\n",
      "\n",
      "Improve ppl percentage (train): 25.4670\n",
      "per-sample abstraction switch ratio: 0.2593 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1538\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 5.10329755343264e-07\n",
      "Iteration 179/200Joint iter 1/1, loss: 1.5180, abs_loss: 0.0079, ssl_loss: 1.5101\n",
      "\n",
      "Improve ppl percentage (train): 25.1655\n",
      "per-sample abstraction switch ratio: 0.1538 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 7, ratio: 0.2500\n",
      " - average advantage over greedy choice: 0.0017\n",
      "Threshold increased to 0.002172554610297084\n",
      "Iteration 180/200Joint iter 1/1, loss: 1.5063, abs_loss: 0.0848, ssl_loss: 1.4215\n",
      "\n",
      "Improve ppl percentage (train): 25.9263\n",
      "per-sample abstraction switch ratio: 0.2500 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 0.00021725543774664402\n",
      "Iteration 181/200Joint iter 1/1, loss: 1.5543, abs_loss: 0.0077, ssl_loss: 1.5466\n",
      "\n",
      "Improve ppl percentage (train): 22.6962\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 0, ratio: 0.0000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 2.1725543774664402e-05\n",
      "Iteration 182/200Joint iter 1/1, loss: 1.4542, abs_loss: 0.0074, ssl_loss: 1.4469\n",
      "\n",
      "Improve ppl percentage (train): 23.6670\n",
      "per-sample abstraction switch ratio: 0.0000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 1, ratio: 0.0385\n",
      " - average advantage over greedy choice: 0.0237\n",
      "Threshold decreased to 0.0\n",
      "Iteration 183/200Joint iter 1/1, loss: 1.5754, abs_loss: 0.0787, ssl_loss: 1.4967\n",
      "\n",
      "Improve ppl percentage (train): 21.3275\n",
      "per-sample abstraction switch ratio: 0.0385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 19, ratio: 0.7600\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 1.9311904964069981e-07\n",
      "Iteration 184/200Joint iter 1/1, loss: 1.5428, abs_loss: 0.0075, ssl_loss: 1.5353\n",
      "\n",
      "Improve ppl percentage (train): 23.4648\n",
      "per-sample abstraction switch ratio: 0.7600 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 17, ratio: 0.6800\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.1243096171019715e-07\n",
      "Iteration 185/200Joint iter 1/1, loss: 1.5515, abs_loss: 0.0077, ssl_loss: 1.5438\n",
      "\n",
      "Improve ppl percentage (train): 23.1544\n",
      "per-sample abstraction switch ratio: 0.6800 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 14, ratio: 0.5385\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.7487277520776843e-07\n",
      "Iteration 186/200Joint iter 1/1, loss: 1.4985, abs_loss: 0.0077, ssl_loss: 1.4907\n",
      "\n",
      "Improve ppl percentage (train): 25.7904\n",
      "per-sample abstraction switch ratio: 0.5385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 15, ratio: 0.5769\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.708100280164217e-07\n",
      "Iteration 187/200Joint iter 1/1, loss: 1.5104, abs_loss: 0.0080, ssl_loss: 1.5024\n",
      "\n",
      "Improve ppl percentage (train): 23.7709\n",
      "per-sample abstraction switch ratio: 0.5769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 14, ratio: 0.5600\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 4.4704697188535647e-07\n",
      "Iteration 188/200Joint iter 1/1, loss: 1.5490, abs_loss: 0.0081, ssl_loss: 1.5409\n",
      "\n",
      "Improve ppl percentage (train): 20.3382\n",
      "per-sample abstraction switch ratio: 0.5600 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 3, ratio: 0.1111\n",
      " - average advantage over greedy choice: 0.0024\n",
      "Threshold decreased to 0.0\n",
      "Iteration 189/200Joint iter 1/1, loss: 1.5543, abs_loss: 0.0785, ssl_loss: 1.4758\n",
      "\n",
      "Improve ppl percentage (train): 24.0170\n",
      "per-sample abstraction switch ratio: 0.1111 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 14, ratio: 0.5385\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.1457671550706436e-07\n",
      "Iteration 190/200Joint iter 1/1, loss: 1.5298, abs_loss: 0.0088, ssl_loss: 1.5210\n",
      "\n",
      "Improve ppl percentage (train): 25.7106\n",
      "per-sample abstraction switch ratio: 0.5385 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 11, ratio: 0.4074\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.1457672971791908e-07\n",
      "Iteration 191/200Joint iter 1/1, loss: 1.4728, abs_loss: 0.0088, ssl_loss: 1.4641\n",
      "\n",
      "Improve ppl percentage (train): 22.6648\n",
      "per-sample abstraction switch ratio: 0.4074 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 14, ratio: 0.5000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.3603439558428363e-07\n",
      "Iteration 192/200Joint iter 1/1, loss: 1.4499, abs_loss: 0.0079, ssl_loss: 1.4419\n",
      "\n",
      "Improve ppl percentage (train): 22.7016\n",
      "per-sample abstraction switch ratio: 0.5000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 16, ratio: 0.5926\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.596378294583701e-07\n",
      "Iteration 193/200Joint iter 1/1, loss: 1.4669, abs_loss: 0.0075, ssl_loss: 1.4594\n",
      "\n",
      "Improve ppl percentage (train): 24.1910\n",
      "per-sample abstraction switch ratio: 0.5926 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 12, ratio: 0.4444\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 2.787351434108132e-07\n",
      "Iteration 194/200Joint iter 1/1, loss: 1.4858, abs_loss: 0.0077, ssl_loss: 1.4781\n",
      "\n",
      "Improve ppl percentage (train): 26.6502\n",
      "per-sample abstraction switch ratio: 0.4444 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 15, ratio: 0.5769\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.579353915483807e-07\n",
      "Iteration 195/200Joint iter 1/1, loss: 1.5020, abs_loss: 0.0071, ssl_loss: 1.4949\n",
      "\n",
      "Improve ppl percentage (train): 21.9774\n",
      "per-sample abstraction switch ratio: 0.5769 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 7, ratio: 0.2593\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 5.084158374302206e-07\n",
      "Iteration 196/200Joint iter 1/1, loss: 1.4769, abs_loss: 0.0070, ssl_loss: 1.4699\n",
      "\n",
      "Improve ppl percentage (train): 22.1633\n",
      "per-sample abstraction switch ratio: 0.2593 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 4, ratio: 0.1429\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 2.2250296183301543e-07\n",
      "Iteration 197/200Joint iter 1/1, loss: 1.4600, abs_loss: 0.0069, ssl_loss: 1.4531\n",
      "\n",
      "Improve ppl percentage (train): 25.6521\n",
      "per-sample abstraction switch ratio: 0.1429 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 15, ratio: 0.6000\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 3.1546727541353903e-07\n",
      "Iteration 198/200Joint iter 1/1, loss: 1.5433, abs_loss: 0.0071, ssl_loss: 1.5362\n",
      "\n",
      "Improve ppl percentage (train): 26.7308\n",
      "per-sample abstraction switch ratio: 0.6000 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 8, ratio: 0.3200\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold increased to 4.27726433827047e-07\n",
      "Iteration 199/200Joint iter 1/1, loss: 1.4997, abs_loss: 0.0071, ssl_loss: 1.4926\n",
      "\n",
      "Improve ppl percentage (train): 25.7252\n",
      "per-sample abstraction switch ratio: 0.3200 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n",
      " - number of switched abstraction: 5, ratio: 0.1786\n",
      " - average advantage over greedy choice: 0.0000\n",
      "Threshold decreased to 1.715186783712852e-07\n",
      "Iteration 200/200Joint iter 1/1, loss: 1.4501, abs_loss: 0.0073, ssl_loss: 1.4428\n",
      "\n",
      "Improve ppl percentage (train): 24.3355\n",
      "per-sample abstraction switch ratio: 0.1786 | t_search: 15 | (How often greedy sample is rejected by other abstraction)\n"
     ]
    }
   ],
   "source": [
    "# Benchmark RL & SSL combination strategies \n",
    "# (I). Pick the best & learn it \n",
    "# -------------------------------------------------------------\n",
    "import copy \n",
    "import wandb\n",
    "import torch\n",
    "from search import compute_ssl_loss, get_batch, eval_search_improvement\n",
    "from search import compute_abs_ssl_loss\n",
    "from search import sorl_search, observe_abstraction, generate_rollout_data, sorl_search_v2\n",
    "from search import compute_curriculum_t_increment, eval_ppl_with_search, curriculum_iter\n",
    "from search import PhaseScheduler, adjust_threshold\n",
    "\n",
    "n = 3 # bigger n seems to destablize the training (?)\n",
    "temperature = 1.0\n",
    " # with n=2, random sample (higher temperature) compared to deterministic search, which is better (?)\n",
    "num_iterations = 200\n",
    "context_length = 1024\n",
    "num_loops = 1\n",
    "global_step = 0 \n",
    "ratio_target = 0.2\n",
    "\n",
    "# Thought: the easier way out is to just increase the threshold? I do recall that threshold itself doesn't help, it only help when combined with \n",
    "#          bigger inner_steps\n",
    "\n",
    "scheduler = PhaseScheduler(init_joint_steps=1, init_abs_switch_ppl_threshold=0.000000)\n",
    "\n",
    "optimizer = torch.optim.Adam(gat.parameters(), lr=1e-3)\n",
    "gat.train() \n",
    "\n",
    "# curriculum\n",
    "t_search = 0\n",
    "t_delta, t_max = compute_curriculum_t_increment(num_iterations=num_iterations, context_length=context_length, K=gat.K, max_ts=max(dataset.lengths),\n",
    "                                                num_loops=num_loops)\n",
    "\n",
    "while global_step < num_iterations: \n",
    "\n",
    "    batch_data = get_batch(dataset.sequences, dataset.lengths, context_length // n, gat.L, gat.K)\n",
    "\n",
    "    t_search = min(t_search + t_delta, t_max)\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        repeat_batch, switch_ratio, rollout_advantages = sorl_search_v2(gat, batch_data, n, temperature, t_search, switch_abs_ppl_threshold=scheduler.abs_switch_ppl_threshold) # pinned greedy sample ver.\n",
    "        \n",
    "        adjust_threshold(switch_ratio, rollout_advantages, scheduler, ratio_target=0.2)\n",
    "        # if t_search > 0: \n",
    "        #     scheduler(switch_ratio=switch_ratio) # step on scheduler when abstraction exists\n",
    "\n",
    "        # update running avg of switch ratio & perform annealing phase change & return 'joint_steps'\n",
    "\n",
    "    for joint_iter in range(scheduler.joint_steps): \n",
    "        ppt = gat(repeat_batch)\n",
    "\n",
    "        ssl_loss = compute_ssl_loss(repeat_batch, ppt)\n",
    "        abs_loss = compute_abs_ssl_loss(repeat_batch, ppt, level=1)\n",
    "\n",
    "        loss = abs_loss + ssl_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clear cache after each iteration\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"Iteration {global_step+1}/{num_iterations}\"\n",
    "                    f\"Joint iter {joint_iter+1}/{scheduler.joint_steps}, loss: {loss.item():.4f}, abs_loss: {abs_loss.item():.4f}, ssl_loss: {ssl_loss.item():.4f}\")\n",
    "\n",
    "        global_step += 1\n",
    "        del loss, abs_loss, ssl_loss\n",
    "    \n",
    "    # train data ppl improvement\n",
    "    improve_ppl_train = eval_search_improvement(gat, batch_data, t_search=t_search)\n",
    "    # scheduler(ppl_improve=improve_ppl_train)\n",
    "    print(f\"\\nImprove ppl percentage (train): {improve_ppl_train:.4f}\")\n",
    "    print(f\"per-sample abstraction switch ratio: {switch_ratio:.4f} | t_search: {t_search} | (How often greedy sample is rejected by other abstraction)\")\n",
    "    # s = observe_abstraction(batch_data, gat, t_search=t_search, temperature=0.0)\n",
    "    # print(s)\n",
    "\n",
    "    # if global_step % 10 == 0: \n",
    "    if False: \n",
    "        val_data = get_batch(id_val_dataset.sequences, id_val_dataset.lengths, context_length, gat.L, gat.K)\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            improve_ppl_val = eval_search_improvement(gat, val_data, t_search=t_search)\n",
    "            print(f\"Improve ppl percentage (val): {improve_ppl_val:.4f}\\n\")\n",
    "        \n",
    "            if t_search == t_max:\n",
    "                traj_ppl_val = eval_ppl_with_search(val_data, gat, dataset.answer_token_id, n=6, temperature=1.0)\n",
    "                print(f\"Traj ppl (val): {traj_ppl_val.mean().item():.4f}\\n\")\n",
    "\n",
    "            if not config.t_curriculum: \n",
    "                traj_ppl_val = eval_generate_ppl(gat, val_data, n=1, temperature=0.0, t_search=t_search).mean()\n",
    "                print(f\"Traj ppl (val): {traj_ppl_val.item():.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_weak_group_argmax_mask(means: torch.Tensor, orig_idx: torch.Tensor, indices: torch.Tensor, switch_abs_ppl_threshold: float = 0.1): \n",
    "    weak_argmax_mask = torch.zeros(len(orig_idx), dtype=torch.bool)\n",
    "    rollout_advantages = torch.zeros(len(orig_idx))\n",
    "\n",
    "    for idx in orig_idx:\n",
    "        sample_mask = (orig_idx == idx)\n",
    "        assert (indices[sample_mask] == indices[sample_mask].sort().values).all(), \"First group is NOT the first appearance\"\n",
    "        \n",
    "        # Pick the best rollout that satisfies the threshold condition\n",
    "        rollout_ppl = means[sample_mask]\n",
    "        greedy_ppl = rollout_ppl[0]\n",
    "        rollout_advantages[sample_mask] = greedy_ppl - rollout_ppl\n",
    "\n",
    "        mask = (rollout_ppl <= greedy_ppl - switch_abs_ppl_threshold)\n",
    "        mask[0] = True\n",
    "\n",
    "        effective_ppl = torch.where(mask, rollout_ppl, torch.tensor(float('inf')))\n",
    "        abs_idx = torch.argmin(effective_ppl)\n",
    "        abs_idx = torch.where(sample_mask)[0][abs_idx]\n",
    "\n",
    "        weak_argmax_mask[abs_idx] = True\n",
    "        \n",
    "    return weak_argmax_mask, rollout_advantages\n",
    "\n",
    "\n",
    "def compute_grouped_weak_argmax(values: torch.Tensor, indices: torch.Tensor, idx_map: torch.Tensor, switch_abs_ppl_threshold: float = 0.1): \n",
    "\n",
    "    # per-current-group mean (current indices)\n",
    "    unique_indices, inverse = torch.unique(indices, return_inverse=True)\n",
    "    n = len(unique_indices)\n",
    "    means = torch.zeros(n).scatter_add_(0, inverse, values) / torch.bincount(inverse).float()\n",
    "\n",
    "    # per-original-group argmax \n",
    "    orig_idx = idx_map[unique_indices]\n",
    "    max_mask, rollout_advantages = compute_weak_group_argmax_mask(means, orig_idx, unique_indices, switch_abs_ppl_threshold)\n",
    "    argmax_indices = unique_indices[max_mask]\n",
    "\n",
    "    # returned indices are in current indices space\n",
    "    return argmax_indices, rollout_advantages[max_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold clipped argmax operator\n",
    "mask = (rollout_ppl <= greedy_ppl - switch_abs_ppl_threshold)\n",
    "mask[0] = True\n",
    "\n",
    "effective_ppl = torch.where(mask, rollout_ppl, torch.tensor(float('inf')))\n",
    "abs_idx = torch.argmin(effective_ppl)\n",
    "\n",
    "abs_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([1, 1, 1, 1, 5, 6]),\n",
       "indices=tensor([0, 1, 2, 3, 4, 5]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 1, 1, 1, 5, 6]).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from search import compute_weak_group_argmax_mask\n",
    "\n",
    "def compute_grouped_weak_argmax(values: torch.Tensor, indices: torch.Tensor, idx_map: torch.Tensor, switch_abs_ppl_threshold: float = 0.1): \n",
    "\n",
    "    # per-current-group mean (current indices)\n",
    "    unique_indices, inverse = torch.unique(indices, return_inverse=True)\n",
    "    n = len(unique_indices)\n",
    "    means = torch.zeros(n).scatter_add_(0, inverse, values) / torch.bincount(inverse).float()\n",
    "\n",
    "    # per-original-group argmax \n",
    "    orig_idx = idx_map[unique_indices]\n",
    "    max_mask, rollout_advantages = compute_weak_group_argmax_mask(means, orig_idx, unique_indices, switch_abs_ppl_threshold)\n",
    "    argmax_indices = unique_indices[max_mask]\n",
    "\n",
    "    # returned indices are in current indices space\n",
    "    return argmax_indices, rollout_advantages[max_mask]\n",
    "\n",
    "compute_grouped_weak_argmax(traj_ppl, traj_idx, repeat_batch.idx_map, switch_abs_ppl_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'commitment'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scheduler.record\n",
    "# scheduler.best_abs_advantage\n",
    "# improve_ppl_train\n",
    "# scheduler.update_advantage(improve_ppl_train)\n",
    "scheduler.phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample 11699 Abstract Tokens at level 1: [1, 1]\\nSample 11700 Abstract Tokens at level 1: [1, 1]\\nSample 11701 Abstract Tokens at level 1: [1, 1, 1, 1, 1]\\nSample 11702 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11703 Abstract Tokens at level 1: [1, 1, 1, 1, 1]\\nSample 11704 Abstract Tokens at level 1: [1, 1, 1]\\nSample 11705 Abstract Tokens at level 1: [1, 1, 1]\\nSample 11706 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11707 Abstract Tokens at level 1: [1, 1]\\nSample 11708 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11709 Abstract Tokens at level 1: [1, 1, 1]\\nSample 11710 Abstract Tokens at level 1: [1, 1, 1, 1, 1]\\nSample 11711 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11712 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11713 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11714 Abstract Tokens at level 1: [1, 1, 1]\\nSample 11715 Abstract Tokens at level 1: [1, 1, 1]\\nSample 11716 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11717 Abstract Tokens at level 1: [1, 1, 1]\\nSample 11718 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11719 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11720 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11721 Abstract Tokens at level 1: [1, 1, 1]\\nSample 11722 Abstract Tokens at level 1: [1, 1, 1]\\nSample 11723 Abstract Tokens at level 1: [1, 1, 1, 1]\\nSample 11724 Abstract Tokens at level 1: [1, 1, 1, 1]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observe_abstraction(batch_data, gat, t_search, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12f098d40>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Toy simulation : \n",
    "# || Initial switch_ratio 0.0, mid switch ratio big, late switch ratio small (but with fluctuations)\n",
    "import torch \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "record = [0.0] * 50 + [abs(torch.rand(1).item() * 20 + 20)/100 for _ in range(100)] + [0.0] * 100 + [abs(torch.rand(1).item() * 8) * (torch.rand(1)>=0.98).item() /100 for _ in range(400)]\n",
    "\n",
    "plt.plot(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07692307692307693"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import eval_generate_ppl\n",
    "\n",
    "with torch.no_grad():\n",
    "    greedy_ppl = eval_generate_ppl(gat, batch_data, 1, temperature=0.0, t_search=t_search)\n",
    "\n",
    "    random_ppl = eval_generate_ppl(gat, batch_data, n, temperature=100.0, t_search=t_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 4, 7, 7, 5, 6, 6, 4, 1, 6, 4, 5, 3, 3, 5, 2, 5, 6, 4, 3, 2, 5, 4, 6,\n",
       "        1, 2, 4, 2, 6, 7, 1, 1, 1, 5, 1, 6, 4, 7, 3, 7, 3, 3, 4, 7, 1, 7, 2, 3,\n",
       "        5, 4, 3, 7, 3, 2, 1, 3, 4, 5, 5, 4, 3, 4, 4, 7, 2, 3, 2, 2, 5, 4, 3, 1,\n",
       "        6, 1, 4, 4, 5, 1, 1, 2, 1, 6, 3, 4, 4, 6, 6, 6, 4, 7, 7, 5, 6, 5, 3, 7,\n",
       "        5, 1, 5, 6, 7, 5, 2, 3, 1, 4, 4, 3, 2, 5, 6, 5, 1, 4, 6, 2, 3, 4, 1, 2,\n",
       "        7, 1, 5, 7, 5, 2, 1, 2, 5, 4, 1, 2, 4, 1, 2, 1, 5, 7, 2, 6, 3, 5, 1, 1,\n",
       "        1, 6, 7, 7, 3, 7, 7, 3, 3, 1, 7, 1, 6, 4, 3, 4, 6, 6, 7, 6, 7, 5, 5, 4,\n",
       "        7, 4, 5, 3, 4, 4, 7, 5, 6, 1, 4, 4, 1, 2, 6, 6, 3, 4, 2, 6, 6, 1, 1, 7,\n",
       "        1, 4, 5, 7, 3, 1, 2, 5, 4, 7, 2, 4, 1, 7, 1, 1, 4, 7, 1, 4, 5, 7, 1, 7,\n",
       "        1, 3, 1, 7, 6, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from search import repeat_hseq, extend_abstract_tokens, pad_abstract_tokens\n",
    "\n",
    "temperature = 100.0\n",
    "\n",
    "repeat_batch = repeat_hseq(batch_data, n)\n",
    "\n",
    "if t_search is not None: \n",
    "    extend_abstract_tokens(repeat_batch, t_search) \n",
    "else: \n",
    "    pad_abstract_tokens(repeat_batch) \n",
    "\n",
    "gat.generate(repeat_batch, parallel=True, temperature=temperature)\n",
    "\n",
    "\n",
    "abstract_mask = (repeat_batch.levels > 0)\n",
    "repeat_batch.tokens[abstract_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4580, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluator for baseline transformer off ? \n",
    "\n",
    "from search import eval_generate_ppl\n",
    "\n",
    "\n",
    "val_data = get_batch(id_val_dataset.sequences, id_val_dataset.lengths, context_length, gat.L, gat.K)\n",
    "# traj_ppl_val = eval_ppl_with_search(val_data, gat, dataset.answer_token_id, n=6, temperature=1.0)\n",
    "\n",
    "# eval_search_improvement(gat, val_data, t_search=t_search)\n",
    "\n",
    "eval_generate_ppl(gat, val_data, n=1, temperature=0.0, t_search=t_search).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.tokens.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierSeq(tokens=tensor([ 9,  2,  0,  ...,  6, 11,  7]), levels=tensor([0, 0, 0,  ..., 0, 0, 0]), timestamps=tensor([ 1,  2,  3,  ..., 11, 12, 13]), sample_idx=tensor([ 0,  0,  0,  ..., 74, 74, 74]), batch_size=75, K=3, L=2, idx_map=tensor([18842, 18843, 18844, 18845, 18846, 18847, 18848, 18849, 18850, 18851,\n",
       "        18852, 18853, 18854, 18855, 18856, 18857, 18858, 18859, 18860, 18861,\n",
       "        18862, 18863, 18864, 18865, 18866, 18842, 18843, 18844, 18845, 18846,\n",
       "        18847, 18848, 18849, 18850, 18851, 18852, 18853, 18854, 18855, 18856,\n",
       "        18857, 18858, 18859, 18860, 18861, 18862, 18863, 18864, 18865, 18866,\n",
       "        18842, 18843, 18844, 18845, 18846, 18847, 18848, 18849, 18850, 18851,\n",
       "        18852, 18853, 18854, 18855, 18856, 18857, 18858, 18859, 18860, 18861,\n",
       "        18862, 18863, 18864, 18865, 18866]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorl_search_v2(gat, batch_data, n, temperature, t_search, switch_abs_ppl_threshold=0.05) # pinned greedy sample ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample 624 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 625 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 626 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 627 Abstract Tokens at level 1: [1, 1, 2]\\nSample 628 Abstract Tokens at level 1: [1, 1, 2]\\nSample 629 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 630 Abstract Tokens at level 1: [1, 1]\\nSample 631 Abstract Tokens at level 1: [1, 2, 1, 2]\\nSample 632 Abstract Tokens at level 1: [1, 2, 1, 2]\\nSample 633 Abstract Tokens at level 1: [1, 1, 2]\\nSample 634 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 635 Abstract Tokens at level 1: [1, 1, 2]\\nSample 636 Abstract Tokens at level 1: [1, 1]\\nSample 637 Abstract Tokens at level 1: [1, 2, 1, 2, 2]\\nSample 638 Abstract Tokens at level 1: [1, 2, 2]\\nSample 639 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 640 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 641 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 642 Abstract Tokens at level 1: [1, 2, 1, 2, 2]\\nSample 643 Abstract Tokens at level 1: [1, 1]\\nSample 644 Abstract Tokens at level 1: [1, 2, 2, 2]\\nSample 645 Abstract Tokens at level 1: [1, 2, 1, 2, 2]\\nSample 646 Abstract Tokens at level 1: [1, 2, 1, 2]\\nSample 647 Abstract Tokens at level 1: [1, 2, 1, 2, 2]\\nSample 648 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 649 Abstract Tokens at level 1: [1, 1, 2]\\nSample 650 Abstract Tokens at level 1: [1, 1, 2]\\nSample 651 Abstract Tokens at level 1: [1, 1, 2]\\nSample 652 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 653 Abstract Tokens at level 1: [1, 2, 1, 2, 2]\\nSample 654 Abstract Tokens at level 1: [1, 2, 2]\\nSample 655 Abstract Tokens at level 1: [1, 1, 2]\\nSample 656 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 657 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 658 Abstract Tokens at level 1: [1, 1, 2]\\nSample 659 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 660 Abstract Tokens at level 1: [1, 1]\\nSample 661 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 662 Abstract Tokens at level 1: [1, 1, 2]\\nSample 663 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 664 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 665 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 666 Abstract Tokens at level 1: [1, 1, 2]\\nSample 667 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 668 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 669 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 670 Abstract Tokens at level 1: [1, 1]\\nSample 671 Abstract Tokens at level 1: [1, 1, 2]\\nSample 672 Abstract Tokens at level 1: [1, 1, 2]\\nSample 673 Abstract Tokens at level 1: [1, 1, 2]\\nSample 674 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 675 Abstract Tokens at level 1: [1, 1, 2]\\nSample 676 Abstract Tokens at level 1: [1, 1, 2]\\nSample 677 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 678 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 679 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 680 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 681 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 682 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 683 Abstract Tokens at level 1: [1, 2, 2, 2]\\nSample 684 Abstract Tokens at level 1: [1, 1, 2, 2]\\nSample 685 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 686 Abstract Tokens at level 1: [1, 1]\\nSample 687 Abstract Tokens at level 1: [1, 1, 2]\\nSample 688 Abstract Tokens at level 1: [1, 1, 2]\\nSample 689 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 690 Abstract Tokens at level 1: [1, 2, 1, 2, 2]\\nSample 691 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 692 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 693 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 694 Abstract Tokens at level 1: [1, 1]\\nSample 695 Abstract Tokens at level 1: [1, 2, 2]\\nSample 696 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 697 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 698 Abstract Tokens at level 1: [1, 2, 1, 2, 2]\\nSample 699 Abstract Tokens at level 1: [1, 2, 1, 2, 2]\\nSample 700 Abstract Tokens at level 1: [1, 1, 1, 2]\\nSample 701 Abstract Tokens at level 1: [1, 1, 2]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = get_batch(id_val_dataset.sequences, id_val_dataset.lengths, context_length, gat.L, gat.K)\n",
    "observe_abstraction(batch_data, gat, t_search, temperature=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = get_batch(dataset.sequences, dataset.lengths, 64, gat.L, gat.K)\n",
    "\n",
    "# Debug on threshold based argmax selection\n",
    "# ------------------------------------------------------------\n",
    "# repeat_batch, switch_ratio = sorl_search_v2(gat, batch_data, n, temperature, t_search, switch_abs_ppl_threshold=0.05)\n",
    "\n",
    "from search import *\n",
    "switch_abs_ppl_threshold=0.05\n",
    "n = 5\n",
    "\n",
    "ref_batch = generate_rollout_data(gat, batch_data, 1, 0.0, t_search)\n",
    "explore_batch = generate_rollout_data(gat, batch_data, n-1, temperature, t_search)\n",
    "ref_batch = concatenate_hseq(ref_batch, explore_batch)\n",
    "ppt = gat(ref_batch)\n",
    "\n",
    "\n",
    "# select | include threshold for weak-argmax selection that retains greedy sample (for stability)\n",
    "# select_batch, switch_ratio = select_best_abstraction(ref_batch, ppt, switch_abs_ppl_threshold=switch_abs_ppl_threshold)\n",
    "\n",
    "repeat_batch = ref_batch\n",
    "traj_mask = (repeat_batch.levels[1:] == 0) & (repeat_batch.timestamps[1:] > 1)\n",
    "traj_idx = repeat_batch.sample_idx[1:][traj_mask]\n",
    "traj_ppl = ppt[traj_mask]\n",
    "\n",
    "argmax_indices = compute_grouped_weak_argmax(traj_ppl, traj_idx, repeat_batch.idx_map, switch_abs_ppl_threshold)\n",
    "\n",
    "# indices, values, idx_map = traj_idx, traj_ppl, repeat_batch.idx_map\n",
    "\n",
    "#  # per-current-group mean (current indices)\n",
    "# unique_indices, inverse = torch.unique(indices, return_inverse=True)\n",
    "# n_indices = len(unique_indices)\n",
    "# means = torch.zeros(n_indices).scatter_add_(0, inverse, values) / torch.bincount(inverse).float()\n",
    "\n",
    "# # per-original-group argmax \n",
    "# orig_idx = idx_map[unique_indices]\n",
    "\n",
    "# max_mask = compute_weak_group_argmax_mask(means, orig_idx, unique_indices, switch_abs_ppl_threshold)\n",
    "# argmax_indices = unique_indices[max_mask]\n",
    "\n",
    "# # weak_argmax_mask = torch.zeros(len(orig_idx), dtype=torch.bool)\n",
    "\n",
    "# # for idx in orig_idx: \n",
    "# #     assert (indices[orig_idx == idx] == indices[orig_idx == idx].sort().values).all(), \"First group is NOT the first appearance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert means.size(0) == unique_indices.size(0) # each idx (rollout) gets a mean ppl\n",
    "assert orig_idx.size(0) == means.size(0) # each mean ppl gets a orig idx\n",
    "assert argmax_indices.size(0) == torch.unique(orig_idx).size(0) # picked indice is for each unique orig idx\n",
    "\n",
    "# repeat_batch.indices\n",
    "# repeat_batch.idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orig_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_best_abstraction(repeat_batch: HierSeq, ppt: torch.Tensor, duplicate: bool = True) -> HierSeq: \n",
    "\"\"\"Pick best abstraction for each sample & repeat to original length\"\"\"\n",
    "# explore\n",
    "n = 3\n",
    "repeat_batch = generate_rollout_data(gat, batch_data, n, temperature, t_search)\n",
    "\n",
    "# evaluate \n",
    "ppt = gat(repeat_batch)\n",
    "\n",
    "from search import * \n",
    "\n",
    "traj_mask = (repeat_batch.levels[1:] == 0) & (repeat_batch.timestamps[1:] > 1)\n",
    "traj_idx = repeat_batch.sample_idx[1:][traj_mask]\n",
    "traj_ppl = ppt[traj_mask]\n",
    "\n",
    "argmax_indices = compute_grouped_argmax(traj_ppl, traj_idx, repeat_batch.idx_map)\n",
    "\n",
    "# ideally we have a statistic here on how much 'switch abstraction' is happening\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [[[]], [[]]],\n",
       "             1: [[[]], [[]]],\n",
       "             2: [[[]], [[]]],\n",
       "             3: [[[]], [[]]],\n",
       "             4: [[[]], [[]]],\n",
       "             5: [[[]], [[]]],\n",
       "             6: [[[]], [[]]],\n",
       "             7: [[[]], [[]]],\n",
       "             8: [[[]], [[]]],\n",
       "             9: [[[]], [[]]],\n",
       "             10: [[[]], [[]]],\n",
       "             11: [[[]], [[]]],\n",
       "             12: [[[]], [[]]],\n",
       "             13: [[[]], [[]]],\n",
       "             14: [[[]], [[]]],\n",
       "             15: [[[]], [[]]],\n",
       "             16: [[[]], [[]]],\n",
       "             17: [[[]], [[]]],\n",
       "             18: [[[]], [[]]],\n",
       "             19: [[[]], [[]]],\n",
       "             20: [[[]], [[]]],\n",
       "             21: [[[]], [[]]],\n",
       "             22: [[[]], [[]]],\n",
       "             23: [[[]], [[]]],\n",
       "             24: [[[]], [[]]],\n",
       "             25: [[[]], [[]]],\n",
       "             26: [[[]], [[]]],\n",
       "             27: [[[]], [[]]]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Record: what is picked for each sample after-all ? \n",
    "# - when training data size is small, the improvement in improve_ppl is big and consistent. \n",
    "# - when training data size is large, the improvement in improve_ppl is small and inconsistent\n",
    "# - small dataset has bigger chance of replaying the same sample ? \n",
    "\n",
    "from utils import HierSeq \n",
    "from collections import defaultdict\n",
    "\n",
    "# version 0: buffer that records abstract tokens for each sample, no perplexity recorded yet\n",
    "class Buffer: \n",
    "    def __init__(self, size: int): \n",
    "        self.size = size\n",
    "        self.record = defaultdict(list)\n",
    "    \n",
    "    def update(self, hseq: HierSeq): \n",
    "        h_seqs, h_timestamps = hseq.to_hierarchical_data()\n",
    "        for i, idx in enumerate(hseq.indices): \n",
    "            if hseq.idx_map is not None: \n",
    "                i = hseq.idx_map[idx] # original index in dataset\n",
    "            self.record[i].append(h_seqs[i][1:]) # record abstract tokens only\n",
    "            self.record[i].append(h_timestamps[i][1:])\n",
    "\n",
    "buffer = Buffer(size=len(dataset.sequences))\n",
    "buffer.update(batch_data)\n",
    "buffer.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataset.sequences)\n",
    "# batch_data.to_hierarchical_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TBD). \n",
    "# 1. Sitch temp=0.0 sampled HierSeq with temp>0.0 sampled HierSeq \n",
    "# 2. Test out improve_ppl of that scheme\n",
    "from search import get_batch, generate_rollout_data, concatenate_hseq\n",
    "from search import select_best_abstraction\n",
    "\n",
    "batch_data = get_batch(dataset.sequences, dataset.lengths, 1024, gat.L, gat.K)\n",
    "\n",
    "t_search = 3\n",
    "temperature = 1.0\n",
    "n = 1\n",
    "\n",
    "# temp=0.0 sampled HierSeq\n",
    "ref_hseq = generate_rollout_data(gat, batch_data, 1, 0.0, t_search)\n",
    "# temp>0.0 sampled HierSeq\n",
    "explore_hseq = generate_rollout_data(gat, batch_data, n, temperature, t_search)\n",
    "# Sitch together (indices need extra care)\n",
    "ref_hseq = concatenate_hseq(ref_hseq, explore_hseq)\n",
    "\n",
    "\n",
    "# evaluate \n",
    "ppt = gat(ref_hseq)\n",
    "\n",
    "# select\n",
    "select_batch = select_best_abstraction(ref_hseq, ppt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about a dynamic temperature adjustment trick?\n",
    "# - buffer only records 'ppl' per sample, and we would keep temperature=0.0 when ppl improve\n",
    "# - when ppl stagnates, we'd increase the temperature a bit. \n",
    "# - given a batch, we'd compute the avg. temperature and apply uniformly on batch\n",
    "# repeat_batch.idx_map\n",
    "from collections import defaultdict\n",
    "\n",
    "buffer = defaultdict(list)\n",
    "\n",
    "\n",
    "batch_data = get_batch(dataset.sequences, dataset.lengths, context_length // n, gat.L, gat.K)\n",
    "\n",
    "for _ in range(100): \n",
    "    ssl_loss = torch.rand(1)\n",
    "    # update buffer\n",
    "    for idx in batch_data.indices: \n",
    "        buffer[idx.item()].append(ssl_loss.item())\n",
    "        buffer[idx.item()] = buffer[idx.item()][-10:]\n",
    "\n",
    "    # compute avg. temperature | increase of ppl => increase temperature  \n",
    "    #                          | drop on ppl_improve => decrease temperature\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7326294779777527,\n",
       " 0.4336777925491333,\n",
       " 0.9438287615776062,\n",
       " 0.5409866571426392,\n",
       " 0.9786422848701477,\n",
       " 0.5516276955604553,\n",
       " 0.7403034567832947,\n",
       " 0.2659739851951599,\n",
       " 0.18815654516220093,\n",
       " 0.2615971565246582]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer[13228]\n",
    "\n",
    "# check ppl decrease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: perhaps we could record ppl advantage against baseline (no abstraction) too? \n",
    "\n",
    "Evaluation: how do we evaluate the model? \n",
    "\n",
    "Incremental sample: what if we generate one abstraction at-a-time, do we still get the same benefit? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides curriculum design, there is a more fundamental problem: the model is not learning to search here. Or rather, the language modeling loss, applied UNIFORMLY to all generated samples teaches the model to NOT DIFFERENTIATE between different choice of abstractions.\n",
    "\n",
    "\n",
    "- language modeling loss is carried out on 'optimal trajectory' $x^{0}$ via minimizing negative log-likelihood $- \\log \\pi^{0}_{\\theta}(x^{0})$, dynamic SFT adopts a variant of $- \\pi^{0}_{\\theta}(x) \\log(\\pi^{0}_{\\theta}(x))$ to focus on 'easy case' and observe better performance than that of baseline model. \n",
    "- policy gradient method applied in GRPO, is basically a form of $- w(x^{1}) \\log \\pi^{1}_{\\theta}(x^{1})$ the absense of optimal trajectory is compensated by a weight proportional to reward signal $r(x^{1})$. The weight adopted here focus on case with high reward / advantage. In the case of SoRL, reward of abstract token are provided by perplexity level of trajectory token, specifically, we have \n",
    "$$\n",
    "r(x^{1}) = \\pi^{0}_{\\theta}(x^{0} | x^{1})\n",
    "$$\n",
    "\n",
    "- we can potentially unify the two things into one loss function, applied to all 'sampled' sequences via \"unified loss\"\n",
    "$$\n",
    "- \\underbrace{\\pi^{0}_{\\theta}(x^{0} | x^{1}) \\cdot \\log \\pi^{1}(x^{1})}_{\\text{Policy Gradient for Abstraction}} - \\underbrace{\\pi^{0}_{\\theta}(x^{0} | x^{1}) \\cdot \\log\\pi^{0}(x^{0})}_{\\text{Dynamic Language Modeling}}\n",
    "$$\n",
    "\n",
    "\n",
    "Above dynamic language modeling loss shrinks exponentially fast (due to exp(-logit) scaling effect) and doesn't work. We revert to a simple generate & pick & train approach with incremental t_search parameter, this significantly improves 'searching ability' of $\\pi^{1}$ -- the picked abstraction $x^{1} \\sim \\pi^{1}(x^{0})$ is significantly better than abstraction selected at random -- it also creates a curriculum that interpolate from language modeling (no abstraction) to abstract modeling. \n",
    "\n",
    "Yep, and my brain just kept telling me there is another way that doesn't require \"discarding\" failing abstraction. \n",
    "\n",
    "But, the most important intuition is this: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: \n",
    "1. pure GRPO leads to negative & decreasing 'improve_ppl_percentage' value -- causing search ability to degrage!\n",
    "2. joint GRPO + SSL training leads to 'improve_ppl_percentage' to increase initialy (first 80 epoch), but then degrades (!). \n",
    "3. joint GRPO + SSL training leads to 'RL_LOSS' to stay negative initially (first 80 epoch), but then goes positive (!). \n",
    "4. generally, accumulated 'rl loss' & 'improve_ppl_percentage' seems to be nagatively correlated -- decrease in rl loss leads to spike in 'improve_ppl_percentage'\n",
    "\n",
    "Observation: \n",
    "- at around 80 iteration, policy collapse. rl_loss drastically increase, and 'improve_ppl_percentage' degrades.\n",
    "- on 80 iteration, we are at the 1st iteration, completed 8 step each consisting of 10 joint iterations, therefore, it's the new data (randomly picked by the 'get_batch' functional) that's causing the policy collapse, this specific data point might be too hard for the current model to solve. But the real question is how do we 'detect' if the case is 'too hard'? \n",
    "\n",
    "Observation: \n",
    "- an error reveals a bad phenomenon, even when we iteratively search on one sample, the quality of rl_loss / ppl_improvement is not improving steadily? \n",
    "- The more basic problem is here: Does the search mechanism work on a single case ?? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
