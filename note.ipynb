{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment (I). Hiearhical Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Hierarchical Sequence K=2 L=3 (aligned by timestamp):\n",
      "-------------------------------------------------------\n",
      "Level 2:                 [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2]             [2] \n",
      "Level 1:         [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1]     [1] \n",
      "Level 0:     [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] \n",
      "=======================================================\n",
      "Total tokens: 350, Max timestamp: 200\n",
      "\n",
      "Epoch 1/20, Loss: 4.158883094787598\n",
      "Epoch 2/20, Loss: 3.982928991317749\n",
      "Epoch 3/20, Loss: 3.7367403507232666\n",
      "Epoch 4/20, Loss: 3.511340379714966\n",
      "Epoch 5/20, Loss: 3.2963905334472656\n",
      "Epoch 6/20, Loss: 3.083921194076538\n",
      "Epoch 7/20, Loss: 2.8711421489715576\n",
      "Epoch 8/20, Loss: 2.660209894180298\n",
      "Epoch 9/20, Loss: 2.454684257507324\n",
      "Epoch 10/20, Loss: 2.249798059463501\n",
      "Epoch 11/20, Loss: 2.0464131832122803\n",
      "Epoch 12/20, Loss: 1.8429228067398071\n",
      "Epoch 13/20, Loss: 1.6336110830307007\n",
      "Epoch 14/20, Loss: 1.4414186477661133\n",
      "Epoch 15/20, Loss: 1.2757917642593384\n",
      "Epoch 16/20, Loss: 1.1157773733139038\n",
      "Epoch 17/20, Loss: 0.9748240113258362\n",
      "Epoch 18/20, Loss: 0.8321359753608704\n",
      "Epoch 19/20, Loss: 0.7076119780540466\n",
      "Epoch 20/20, Loss: 0.6049309372901917\n"
     ]
    }
   ],
   "source": [
    "# The issue with this counting sequence is that it has batch size of 1 only \n",
    "# it's fine for now, but clearly a fourier series decomposition is more beautiful\n",
    "\n",
    "# (I). Counting Sequence\n",
    "# --------------------------------------------------------------------------------\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "# (I.1) Generate Counting Sequence\n",
    "# ----------------------------------------------------\n",
    "def generate_level(l: int, seq: list, t: int, L: int, K: int): \n",
    "    if l < L:\n",
    "        seq[l] += str(l)\n",
    "        if t % K == 0: \n",
    "            return generate_level(l+1, seq, t // K, L, K)\n",
    "    return seq\n",
    "\n",
    "def generate_count_seq(L: int, K: int, T: int): \n",
    "    seq = defaultdict(str)\n",
    "    for t in range(1, T+1): \n",
    "        seq = generate_level(0, seq, t, L, K)\n",
    "    return seq\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# (I.2) Tokenizer (basic integer tokenizer)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "class TinyTokenizer: \n",
    "    def __init__(self, vocab: dict):\n",
    "        self.vocab = {str(k): v for k, v in vocab.items()}\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "    def __call__(self, seq: str):\n",
    "        return [self.vocab[c] for c in seq]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "# (I.3) Tensor idx sequence preparation \n",
    "# ----------------------------------------------------\n",
    "\n",
    "L = 3\n",
    "K = 2\n",
    "T = 200\n",
    "\n",
    "data = generate_count_seq(L, K, T)\n",
    "tokenizer = TinyTokenizer({str(k): k for k in range(10)})\n",
    "\n",
    "idx = [tokenizer(seq) for seq in data.values()]\n",
    "idx += [[] for _ in range(L - len(idx))]\n",
    "samples = [(idx, None)]\n",
    "\n",
    "from model import GATConfig, GAT, HierSeq\n",
    "from utils import stream_print_hseq\n",
    "from torch.optim import Adam \n",
    "\n",
    "config = GATConfig(K=K, L=L, n_embd=128, n_head=4, device=\"cpu\", _compile=False)\n",
    "gat = GAT(config)\n",
    "\n",
    "# .from_hiearchical_data has error: prepared token is NOT interleaved with correct causal ordering\n",
    "batch_data = HierSeq.from_hierarchical_data(samples, K=gat.K, L=gat.L)\n",
    "stream_print_hseq(batch_data) # sanity check\n",
    "\n",
    "# Batched Forward Propagation\n",
    "epochs = 20\n",
    "# gat.train()\n",
    "\n",
    "\n",
    "# Training Loop : learning just fine -- loss reduces quickly\n",
    "# ----------------------------------------------------\n",
    "optimizer = Adam(gat.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = gat(batch_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "    # break\n",
    "# ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Hierarchical Sequence K=2 L=3 (aligned by timestamp):\n",
      "-------------------------------------------------------\n",
      "Level 2:                 [2]             [2]             [2]                 \n",
      "Level 1:         [1]     [1]     [1]     [1]     [1]     [1]     [1]         \n",
      "Level 0:     [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] \n",
      "=======================================================\n",
      "Total tokens: 26, Max timestamp: 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import * \n",
    "\n",
    "\n",
    "test_data = generate_count_seq(L, K, 1)\n",
    "idx = [tokenizer(seq) for seq in test_data.values()]\n",
    "idx += [[] for _ in range(L - len(idx))]\n",
    "test_samples = [(idx, None)]\n",
    "test_batch_data = HierSeq.from_hierarchical_data(test_samples, K=gat.K, L=gat.L)\n",
    "\n",
    "\n",
    "for _ in range(25): \n",
    "    gat.generate(test_batch_data)\n",
    "    stream_print_hseq(test_batch_data)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-Organizing Reinforcement Learning\n",
    "1. A more exciting question is how can I build a GAT module for a Snake game? It'll be the natural test-bed for SoRL -- a snake with inner-monologue. \n",
    "2. Decision Abstractive Transformer (DAT).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Episode 0: Score=0, Reward=-10.6\n",
      "Episode 1: Score=0, Reward=-11.0\n",
      "Episode 2: Score=0, Reward=-11.700000000000001\n",
      "Episode 3: Score=0, Reward=-12.3\n",
      "Episode 4: Score=1, Reward=-1.5999999999999996\n",
      "Sanity check passed: total 161 0-th level tokens (state & action)\n",
      "Sanity check passed: 83 state tokens in data, 83 state tokens in trajectories\n",
      "Sanity check passed: 78 action tokens in data, 78 action tokens in trajectories\n",
      "Sanity check passed: 191 (action/state/abstract) tokens in data\n"
     ]
    }
   ],
   "source": [
    "from snake import SnakeGameEngine, collect_trajectories, RandomAgent\n",
    "from utils import HierTraj, data_sanity_check\n",
    "from constant import PLACE_HOLDER_STATE_TOK, PLACE_HOLDER_ACTION_TOK\n",
    "\n",
    "env = SnakeGameEngine(width=10, height=10)\n",
    "\n",
    "# Collect trajectories\n",
    "trajectories = collect_trajectories(env, RandomAgent(env), num_episodes=5, device=\"cpu\")\n",
    "\n",
    "samples = []\n",
    "for trajectory in trajectories: \n",
    "\n",
    "    n_state = trajectory[0].size(0)\n",
    "    placeholder_tokens = [PLACE_HOLDER_STATE_TOK if i % 2 == 0 else PLACE_HOLDER_ACTION_TOK for i in range(2*n_state-1)]\n",
    "    sample = ([placeholder_tokens, [3, 9, 4, 2], [19, 14]], None)\n",
    "    samples.append(sample)\n",
    "\n",
    "batch_data = HierTraj.from_hierarchical_data(samples, K=3, L=3)\n",
    "data_sanity_check(batch_data, trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DAT, DATConfig\n",
    "\n",
    "# DAT model \n",
    "\n",
    "config = DATConfig(\n",
    "    n_layer=4,\n",
    "    n_head=2,\n",
    "    n_embd=32,\n",
    "    K=2,\n",
    "    L=3,\n",
    "    vocab_size_list=[64, 32],\n",
    "    device=\"cpu\",\n",
    "    _compile=True,\n",
    ")\n",
    "\n",
    "# Snake specific encoder & decoder for state & action\n",
    "from snake import StateEncoder, StateDecoder, ActionEncoder, ActionDecoder\n",
    "\n",
    "state_encoder = StateEncoder(height=10, width=10, feature_dim=config.n_embd)\n",
    "state_decoder = StateDecoder(height=10, width=10, feature_dim=config.n_embd)\n",
    "action_encoder = ActionEncoder(action_size=4, feature_dim=config.n_embd)\n",
    "action_decoder = ActionDecoder(action_size=4, feature_dim=config.n_embd)\n",
    "\n",
    "dat = DAT(config, state_encoder, state_decoder, action_encoder, action_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss\n",
    "loss = dat(batch_data, trajectories)\n",
    "\n",
    "# generate & update \n",
    "new_batch_data, new_trajectories = dat.generate(batch_data, trajectories)\n",
    "\n",
    "# act: produce action tokens (if there already exists action-tokens un-grounded with reward, skip it)\n",
    "pairs = dat.act(batch_data, trajectories) # list of (sample_idx, action_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Hierarchical Trajectory K=2 L=3 (aligned by timestamp):\n",
      "-------------------------------------------------------\n",
      "Level 2:              [0]             [0]             [0]                 \n",
      "Level 1:      [0]     [0]     [0]     [0]     [0]     [0]     [0]         \n",
      "L0-State: [s] [s] [s] [s] [s] [s] [s] [s] [s] [s] [s] [s] [s] [s] [s] [s] \n",
      "L0-Action:    [a] [a] [a] [a] [a] [a] [a] [a] [a] [a] [a] [a] [a] [a] [a] \n",
      "=======================================================\n",
      "Total tokens: 41, Max timestamp: 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate on 'order of generation'\n",
    "from utils import test_dat_gen_order\n",
    "\n",
    "# Sanity check-up function (order of generation)\n",
    "test_dat_gen_order(dat, env, L=3, K=2, n_gen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does DAT dream of playing snake game?\n",
    "\n",
    "\n",
    "from agent import HiearchicalAgent\n",
    "from snake import SnakeGameEngine\n",
    "\n",
    "# Environment\n",
    "env = SnakeGameEngine(width=10, height=10)\n",
    "# Initial obs\n",
    "init_obs = env.reset()\n",
    "# DAT agent \n",
    "dat_dude = HiearchicalAgent(dat, init_obs, \"cpu\")\n",
    "\n",
    "# TBD: \n",
    "# - implement the 'environment feedback' function \n",
    "# - update on trajectory based on environment feedback \n",
    "# - visualize a clueless DAT dude playing snake game\n",
    "# - implement DRA algorithm and into DAT dude / DAT module\n",
    "# - one step closer into SoRL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_dude.act(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRA, Hyperball trick, SoRL\n",
    "\n",
    "def discovery_refinement_advantage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative studies required between GAT and other hiearchical models, such as 'adaptive-chunk', 'byte-latent', 'hiearchical-reasoning', 'JEPA' to name a few. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
