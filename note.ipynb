{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{SoRL (GAT)}$\n",
    "1. Group advantage computation \n",
    "2. Surrogate loss computation\n",
    "\n",
    "The key for learning from experience is learning from failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 621700.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2000 sequences to dataset/multiplication/2K-123.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset.arithmetic import ArithmeticDataset\n",
    "\n",
    "dataset = ArithmeticDataset(\n",
    "    min_digit=1,\n",
    "    max_digit=3,\n",
    "    num_data=2000,\n",
    "    filepath=\"dataset/multiplication/2K-123.bin\"\n",
    ").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized GAT model\n"
     ]
    }
   ],
   "source": [
    "from src import GATConfig, GAT\n",
    "from src.sorl import SORLConfig\n",
    "import torch \n",
    "from dataset.arithmetic import ArithmeticDataset\n",
    "\n",
    "dataset = ArithmeticDataset.from_file(\"dataset/multiplication/2K-123.bin\")\n",
    "\n",
    "# 1. Setup a dummy model and data\n",
    "config = GATConfig(L=2, K=3, vocab_size_list=[dataset.vocab_size_list[0], 5], device='cpu')\n",
    "model = GAT(config)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "print(f\"Initialized GAT model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import infer_level\n",
    "from copy import deepcopy \n",
    "from src.sorl import prep_denoise\n",
    "from dataset.base import get_batch\n",
    "\n",
    "data = get_batch(dataset, batch_size=10, max_length=1024, pad_token_id=model.level_mask_tokens[0])\n",
    "\n",
    "# forward propagation : compute perplexity per token (traj & abstract)\n",
    "idx = data[:, :-1].contiguous().clone()\n",
    "target = data[:, 1:].contiguous().clone() \n",
    "ppt = model(idx, target)\n",
    "\n",
    "# causal generate return next_token (1 per sample)\n",
    "idx = data.contiguous()\n",
    "next_idx, kv_cache, levels = model.generate(idx, temperature=0.0)\n",
    "next_idx, kv_cache, levels = model.generate(next_idx.unsqueeze(1), temperature=0.0, kv_cache=kv_cache, levels=levels)\n",
    "\n",
    "# parallel denoise (return updated token sequence) \n",
    "levels = infer_level(idx, model.vocab_sizes, model.level_mask_tokens[0])\n",
    "denoise_mask = levels.bool() # toy denoise mask\n",
    "denoise_mask[1, 0] = True \n",
    "denoise_mask[1, 1] = True \n",
    "\n",
    "from src import pad_abstract_tokens\n",
    "# denoise | it conduct in-place update\n",
    "denoise_idx = deepcopy(idx)\n",
    "l = 1\n",
    "denoise_idx = pad_abstract_tokens(denoise_idx, model, l, use_rhythmic_placeholders=True)\n",
    "denoise_mask, denoise_levels = prep_denoise(denoise_idx, model)\n",
    "\n",
    "denoise_idx = model.denoise(denoise_idx, denoise_mask, denoise_levels, temperature=0.0) # denoise return an updated idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# sorl_search(data, model, sorl_config)\n",
    "# from src.sorl import heuristic_rollout, chunk_denoise, infer_timestamp\n",
    "# search_data, search_data_idx = heuristic_rollout(data, model, l=config.l, n=config.n-1, temperature=config.temperature, steps=config.steps, max_t_search=config.max_t_search, start_ts=config.start_ts, end_ts=config.end_ts, use_spike_placeholders=config.use_spike_placeholders, abstract_budget=config.abstract_budget, use_rhythmic_placeholders=config.use_rhythmic_placeholders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100, loss: 4.9127, abs_loss: 2.0794, ssl_loss: 2.8332\n",
      "Iteration 2/100, loss: 4.7362, abs_loss: 1.9370, ssl_loss: 2.7991\n",
      "Iteration 3/100, loss: 4.4892, abs_loss: 1.7341, ssl_loss: 2.7552\n",
      "Iteration 4/100, loss: 4.2146, abs_loss: 1.5094, ssl_loss: 2.7052\n",
      "Iteration 5/100, loss: 3.9717, abs_loss: 1.3026, ssl_loss: 2.6691\n",
      "Iteration 6/100, loss: 3.7408, abs_loss: 1.1191, ssl_loss: 2.6218\n",
      "Iteration 7/100, loss: 3.5362, abs_loss: 0.9555, ssl_loss: 2.5807\n",
      "Iteration 8/100, loss: 3.3784, abs_loss: 0.8085, ssl_loss: 2.5699\n",
      "Iteration 9/100, loss: 3.2184, abs_loss: 0.6780, ssl_loss: 2.5404\n",
      "Iteration 10/100, loss: 3.0805, abs_loss: 0.5644, ssl_loss: 2.5161\n",
      "Iteration 11/100, loss: 2.9727, abs_loss: 0.4672, ssl_loss: 2.5055\n",
      "Iteration 12/100, loss: 2.8609, abs_loss: 0.3852, ssl_loss: 2.4758\n",
      "Iteration 13/100, loss: 2.7815, abs_loss: 0.3173, ssl_loss: 2.4642\n",
      "Iteration 14/100, loss: 2.7241, abs_loss: 0.2617, ssl_loss: 2.4625\n",
      "Iteration 15/100, loss: 2.6535, abs_loss: 0.2164, ssl_loss: 2.4371\n",
      "Iteration 16/100, loss: 2.6034, abs_loss: 0.1799, ssl_loss: 2.4236\n",
      "Iteration 17/100, loss: 2.5715, abs_loss: 0.1504, ssl_loss: 2.4211\n",
      "Iteration 18/100, loss: 2.5845, abs_loss: 0.1267, ssl_loss: 2.4578\n",
      "Iteration 19/100, loss: 2.5641, abs_loss: 0.1076, ssl_loss: 2.4565\n",
      "Iteration 20/100, loss: 2.5013, abs_loss: 0.0923, ssl_loss: 2.4090\n",
      "Iteration 21/100, loss: 2.5002, abs_loss: 0.0800, ssl_loss: 2.4202\n",
      "Iteration 22/100, loss: 2.4817, abs_loss: 0.0702, ssl_loss: 2.4116\n",
      "Iteration 23/100, loss: 2.4443, abs_loss: 0.0625, ssl_loss: 2.3818\n",
      "Iteration 24/100, loss: 2.4127, abs_loss: 0.0571, ssl_loss: 2.3557\n",
      "Iteration 25/100, loss: 2.3909, abs_loss: 0.0548, ssl_loss: 2.3362\n",
      "Iteration 26/100, loss: 2.3698, abs_loss: 0.0580, ssl_loss: 2.3118\n",
      "Iteration 27/100, loss: 2.3406, abs_loss: 0.0682, ssl_loss: 2.2724\n",
      "Iteration 28/100, loss: 2.3350, abs_loss: 0.0759, ssl_loss: 2.2591\n",
      "Iteration 29/100, loss: 2.3110, abs_loss: 0.0749, ssl_loss: 2.2361\n",
      "Iteration 30/100, loss: 2.2971, abs_loss: 0.0671, ssl_loss: 2.2300\n",
      "Iteration 31/100, loss: 2.2696, abs_loss: 0.0614, ssl_loss: 2.2081\n",
      "Iteration 32/100, loss: 2.2340, abs_loss: 0.0585, ssl_loss: 2.1755\n",
      "Iteration 33/100, loss: 2.1928, abs_loss: 0.0580, ssl_loss: 2.1348\n",
      "Iteration 34/100, loss: 2.1545, abs_loss: 0.0579, ssl_loss: 2.0966\n",
      "Iteration 35/100, loss: 2.1315, abs_loss: 0.0521, ssl_loss: 2.0794\n",
      "Iteration 36/100, loss: 2.1179, abs_loss: 0.0470, ssl_loss: 2.0709\n",
      "Iteration 37/100, loss: 2.1086, abs_loss: 0.0387, ssl_loss: 2.0699\n",
      "Iteration 38/100, loss: 2.0646, abs_loss: 0.0330, ssl_loss: 2.0316\n",
      "Iteration 39/100, loss: 2.0454, abs_loss: 0.0351, ssl_loss: 2.0103\n",
      "Iteration 40/100, loss: 2.0231, abs_loss: 0.0392, ssl_loss: 1.9839\n",
      "Iteration 41/100, loss: 1.9984, abs_loss: 0.0415, ssl_loss: 1.9569\n",
      "Iteration 42/100, loss: 1.9670, abs_loss: 0.0415, ssl_loss: 1.9255\n",
      "Iteration 43/100, loss: 1.9091, abs_loss: 0.0348, ssl_loss: 1.8743\n",
      "Iteration 44/100, loss: 1.9043, abs_loss: 0.0348, ssl_loss: 1.8695\n",
      "Iteration 45/100, loss: 1.8752, abs_loss: 0.0376, ssl_loss: 1.8376\n",
      "Iteration 46/100, loss: 1.8536, abs_loss: 0.0394, ssl_loss: 1.8142\n",
      "Iteration 47/100, loss: 1.8112, abs_loss: 0.0357, ssl_loss: 1.7755\n",
      "Iteration 48/100, loss: 1.8255, abs_loss: 0.0337, ssl_loss: 1.7918\n",
      "Iteration 49/100, loss: 1.7972, abs_loss: 0.0298, ssl_loss: 1.7675\n",
      "Iteration 50/100, loss: 1.7900, abs_loss: 0.0246, ssl_loss: 1.7654\n",
      "Iteration 51/100, loss: 1.7748, abs_loss: 0.0204, ssl_loss: 1.7544\n",
      "Iteration 52/100, loss: 1.7417, abs_loss: 0.0211, ssl_loss: 1.7206\n",
      "Iteration 53/100, loss: 1.7457, abs_loss: 0.0234, ssl_loss: 1.7224\n",
      "Iteration 54/100, loss: 1.7216, abs_loss: 0.0219, ssl_loss: 1.6997\n",
      "Iteration 55/100, loss: 1.7277, abs_loss: 0.0199, ssl_loss: 1.7079\n",
      "Iteration 56/100, loss: 1.7184, abs_loss: 0.0228, ssl_loss: 1.6955\n",
      "Iteration 57/100, loss: 1.6990, abs_loss: 0.0195, ssl_loss: 1.6795\n",
      "Iteration 58/100, loss: 1.6785, abs_loss: 0.0156, ssl_loss: 1.6629\n",
      "Iteration 59/100, loss: 1.6704, abs_loss: 0.0141, ssl_loss: 1.6563\n",
      "Iteration 60/100, loss: 1.6587, abs_loss: 0.0138, ssl_loss: 1.6449\n",
      "Iteration 61/100, loss: 1.6630, abs_loss: 0.0148, ssl_loss: 1.6482\n",
      "Iteration 62/100, loss: 1.6686, abs_loss: 0.0155, ssl_loss: 1.6531\n",
      "Iteration 63/100, loss: 1.6346, abs_loss: 0.0158, ssl_loss: 1.6188\n",
      "Iteration 64/100, loss: 1.6457, abs_loss: 0.0138, ssl_loss: 1.6318\n",
      "Iteration 65/100, loss: 1.6293, abs_loss: 0.0131, ssl_loss: 1.6162\n",
      "Iteration 66/100, loss: 1.5948, abs_loss: 0.0114, ssl_loss: 1.5834\n",
      "Iteration 67/100, loss: 1.6046, abs_loss: 0.0102, ssl_loss: 1.5944\n",
      "Iteration 68/100, loss: 1.5687, abs_loss: 0.0100, ssl_loss: 1.5586\n",
      "Iteration 69/100, loss: 1.5944, abs_loss: 0.0107, ssl_loss: 1.5837\n",
      "Iteration 70/100, loss: 1.5895, abs_loss: 0.0114, ssl_loss: 1.5782\n",
      "Iteration 71/100, loss: 1.5754, abs_loss: 0.0119, ssl_loss: 1.5635\n",
      "Iteration 72/100, loss: 1.5757, abs_loss: 0.0116, ssl_loss: 1.5640\n",
      "Iteration 73/100, loss: 1.5537, abs_loss: 0.0101, ssl_loss: 1.5435\n",
      "Iteration 74/100, loss: 1.5492, abs_loss: 0.0109, ssl_loss: 1.5383\n",
      "Iteration 75/100, loss: 1.5599, abs_loss: 0.0116, ssl_loss: 1.5484\n",
      "Iteration 76/100, loss: 1.5571, abs_loss: 0.0126, ssl_loss: 1.5446\n",
      "Iteration 77/100, loss: 1.5394, abs_loss: 0.0131, ssl_loss: 1.5263\n",
      "Iteration 78/100, loss: 1.5390, abs_loss: 0.0121, ssl_loss: 1.5269\n",
      "Iteration 79/100, loss: 1.5456, abs_loss: 0.0104, ssl_loss: 1.5352\n",
      "Iteration 80/100, loss: 1.5116, abs_loss: 0.0097, ssl_loss: 1.5019\n",
      "Iteration 81/100, loss: 1.5463, abs_loss: 0.0092, ssl_loss: 1.5370\n",
      "Iteration 82/100, loss: 1.5069, abs_loss: 0.0087, ssl_loss: 1.4982\n",
      "Iteration 83/100, loss: 1.5160, abs_loss: 0.0092, ssl_loss: 1.5067\n",
      "Iteration 84/100, loss: 1.4968, abs_loss: 0.0086, ssl_loss: 1.4882\n",
      "Iteration 85/100, loss: 1.5397, abs_loss: 0.0079, ssl_loss: 1.5318\n",
      "Iteration 86/100, loss: 1.5272, abs_loss: 0.0076, ssl_loss: 1.5196\n",
      "Iteration 87/100, loss: 1.5037, abs_loss: 0.0073, ssl_loss: 1.4964\n",
      "Iteration 88/100, loss: 1.5219, abs_loss: 0.0069, ssl_loss: 1.5150\n",
      "Iteration 89/100, loss: 1.5130, abs_loss: 0.0067, ssl_loss: 1.5063\n",
      "Iteration 90/100, loss: 1.5185, abs_loss: 0.0068, ssl_loss: 1.5117\n",
      "Iteration 91/100, loss: 1.4859, abs_loss: 0.0068, ssl_loss: 1.4792\n",
      "Iteration 92/100, loss: 1.5157, abs_loss: 0.0069, ssl_loss: 1.5088\n",
      "Iteration 93/100, loss: 1.5358, abs_loss: 0.0065, ssl_loss: 1.5293\n",
      "Iteration 94/100, loss: 1.5017, abs_loss: 0.0062, ssl_loss: 1.4955\n",
      "Iteration 95/100, loss: 1.4980, abs_loss: 0.0061, ssl_loss: 1.4920\n",
      "Iteration 96/100, loss: 1.5126, abs_loss: 0.0059, ssl_loss: 1.5068\n",
      "Iteration 97/100, loss: 1.5113, abs_loss: 0.0057, ssl_loss: 1.5056\n",
      "Iteration 98/100, loss: 1.5152, abs_loss: 0.0055, ssl_loss: 1.5097\n",
      "Iteration 99/100, loss: 1.4803, abs_loss: 0.0054, ssl_loss: 1.4749\n",
      "Iteration 100/100, loss: 1.4921, abs_loss: 0.0055, ssl_loss: 1.4866\n"
     ]
    }
   ],
   "source": [
    "# Record & Save an annotated dataset\n",
    "\n",
    "# from dataset.base import BaseHierDataset\n",
    "from dataset.arithmetic import ArithmeticHierDataset\n",
    "from nil import annotate_abstraction\n",
    "from nil import supervise_gat \n",
    "\n",
    "record_dataset = ArithmeticHierDataset.from_dataset(dataset)\n",
    "\n",
    "# Greedy Abstraction Annotation (Passing knowledge to the next generation)\n",
    "# ------------------------------------------------------------------------\n",
    "record_dataset = annotate_abstraction(record_dataset, gat)\n",
    "\n",
    "\n",
    "# Reset GAT module\n",
    "# -------------------\n",
    "gat = GAT(gat_config)\n",
    "\n",
    "\n",
    "# Weak Supervision (GAT)\n",
    "# ------------------------------------------------------------------------\n",
    "weak_iterations = 100 # require tuning\n",
    "context_length = 1024\n",
    "\n",
    "supervised_gat = supervise_gat(record_dataset, gat, weak_iterations, context_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep it beautifully simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import sorl_search, SORLConfig\n",
    "from dataset.arithmetic import ArithmeticDataset\n",
    "from src import GATConfig, GAT\n",
    "\n",
    "sorl_config = SORLConfig(\n",
    "    n = 2,\n",
    "    temperature = 0.75,   \n",
    "    # rollout specific \n",
    "    causal_rollout=False, \n",
    "    \n",
    "    l=1,\n",
    "    steps=1,\n",
    "    use_rhythmic_placeholders=True,\n",
    "    use_spike_placeholders=True,\n",
    "    abstract_budget=5,\n",
    "    max_t_search=5,\n",
    "\n",
    "    # memory fading\n",
    "    max_seq_len = 17,\n",
    "    use_fade_memory=True,\n",
    "    min_keep=6,\n",
    "\n",
    "    # dataset specific\n",
    "    train_dataset_path=\"dataset/multiplication/2K-123.bin\",\n",
    "    val_dataset_path=\"dataset/multiplication/2K-123.bin\",\n",
    "    train_batch_size=24,\n",
    "    val_batch_size=1,\n",
    "    train_iterations=400,\n",
    "    val_iterations=1,\n",
    "    # optimization\n",
    "    learning_rate=1e-3, \n",
    "    log_interval=10\n",
    ")\n",
    "\n",
    "train_dataset = ArithmeticDataset.from_file(sorl_config.train_dataset_path)\n",
    "val_dataset = ArithmeticDataset.from_file(sorl_config.val_dataset_path)\n",
    "traj_vocab_size = train_dataset.vocab_size_list[0]\n",
    "\n",
    "gat_config = GATConfig(K=3, L=2, n_embd=128, n_head=4, n_layer=4, device=\"cpu\", _compile=False,\n",
    "                       vocab_size_list=[traj_vocab_size, 8], memory_span=sorl_config.max_length)\n",
    "\n",
    "gat = GAT(gat_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/400 - loss: 3.1780, abs_loss: 0.0000, ssl_loss: 3.1780, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 2/400 - loss: 3.1347, abs_loss: 0.0000, ssl_loss: 3.1347, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 3/400 - loss: 3.0570, abs_loss: 0.0000, ssl_loss: 3.0570, search_ppl: -0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 4/400 - loss: 2.9704, abs_loss: 0.0000, ssl_loss: 2.9704, search_ppl: -0.0002, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 5/400 - loss: 2.8999, abs_loss: 0.0000, ssl_loss: 2.8999, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 6/400 - loss: 2.8177, abs_loss: 0.0000, ssl_loss: 2.8177, search_ppl: -0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 7/400 - loss: 2.7410, abs_loss: 0.0000, ssl_loss: 2.7410, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 8/400 - loss: 2.6677, abs_loss: 0.0000, ssl_loss: 2.6677, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 9/400 - loss: 2.6193, abs_loss: 0.0000, ssl_loss: 2.6193, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 10/400 - loss: 2.5582, abs_loss: 0.0000, ssl_loss: 2.5582, search_ppl: -0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 11/400 - loss: 2.4795, abs_loss: 0.0000, ssl_loss: 2.4795, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 12/400 - loss: 2.4161, abs_loss: 0.0000, ssl_loss: 2.4161, search_ppl: -0.0002, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 13/400 - loss: 2.3473, abs_loss: 0.0000, ssl_loss: 2.3473, search_ppl: -0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 14/400 - loss: 2.3316, abs_loss: 0.0000, ssl_loss: 2.3316, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 15/400 - loss: 2.2794, abs_loss: 0.0000, ssl_loss: 2.2794, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 16/400 - loss: 2.2291, abs_loss: 0.0000, ssl_loss: 2.2291, search_ppl: -0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 16\n",
      "Iteration 17/400 - loss: 2.1443, abs_loss: 0.0000, ssl_loss: 2.1443, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 18/400 - loss: 2.1338, abs_loss: 0.0000, ssl_loss: 2.1338, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 19/400 - loss: 2.0840, abs_loss: 0.0000, ssl_loss: 2.0840, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 20/400 - loss: 2.0148, abs_loss: 0.0000, ssl_loss: 2.0148, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 21/400 - loss: 2.0054, abs_loss: 0.0000, ssl_loss: 2.0054, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 22/400 - loss: 1.9434, abs_loss: 0.0000, ssl_loss: 1.9434, search_ppl: -0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 23/400 - loss: 1.9810, abs_loss: 0.0000, ssl_loss: 1.9810, search_ppl: -0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 24/400 - loss: 1.8569, abs_loss: 0.0000, ssl_loss: 1.8569, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 25/400 - loss: 1.8310, abs_loss: 0.0000, ssl_loss: 1.8310, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 26/400 - loss: 1.8394, abs_loss: 0.0000, ssl_loss: 1.8394, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 27/400 - loss: 1.7737, abs_loss: 0.0000, ssl_loss: 1.7737, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 28/400 - loss: 1.8834, abs_loss: 0.0000, ssl_loss: 1.8834, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 29/400 - loss: 1.8556, abs_loss: 0.0000, ssl_loss: 1.8556, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 30/400 - loss: 1.8321, abs_loss: 0.0000, ssl_loss: 1.8321, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 31/400 - loss: 1.8643, abs_loss: 0.0000, ssl_loss: 1.8643, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 32/400 - loss: 1.8296, abs_loss: 0.0000, ssl_loss: 1.8296, search_ppl: 0.0003, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 15\n",
      "Iteration 33/400 - loss: 1.8208, abs_loss: 0.0000, ssl_loss: 1.8208, search_ppl: -0.0003, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 34/400 - loss: 1.7871, abs_loss: 0.0000, ssl_loss: 1.7871, search_ppl: -0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 35/400 - loss: 1.7819, abs_loss: 0.0000, ssl_loss: 1.7819, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 36/400 - loss: 1.8223, abs_loss: 0.0000, ssl_loss: 1.8223, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 37/400 - loss: 1.7188, abs_loss: 0.0000, ssl_loss: 1.7188, search_ppl: -0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 38/400 - loss: 1.7142, abs_loss: 0.0000, ssl_loss: 1.7142, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 39/400 - loss: 1.6688, abs_loss: 0.0000, ssl_loss: 1.6688, search_ppl: -0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 40/400 - loss: 1.8162, abs_loss: 0.0000, ssl_loss: 1.8162, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 41/400 - loss: 1.7391, abs_loss: 0.0000, ssl_loss: 1.7391, search_ppl: -0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 42/400 - loss: 1.6959, abs_loss: 0.0000, ssl_loss: 1.6959, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 43/400 - loss: 1.7382, abs_loss: 0.0000, ssl_loss: 1.7382, search_ppl: -0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 44/400 - loss: 1.7177, abs_loss: 0.0000, ssl_loss: 1.7177, search_ppl: -0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 45/400 - loss: 1.7239, abs_loss: 0.0000, ssl_loss: 1.7239, search_ppl: -0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 46/400 - loss: 1.7122, abs_loss: 0.0000, ssl_loss: 1.7122, search_ppl: 0.0001, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 47/400 - loss: 1.6265, abs_loss: 0.0000, ssl_loss: 1.6265, search_ppl: 0.0000, switch_ratio: 0.0000, vocab_util: 0.0000, t_search: 0, memory_span: 14\n",
      "Iteration 48/400 - loss: 8.2412, abs_loss: 6.3015, ssl_loss: 1.9397, search_ppl: -1.4725, switch_ratio: 0.5000, vocab_util: 0.7778, t_search: 1, memory_span: 13\n",
      "Iteration 49/400 - loss: 7.5709, abs_loss: 5.7776, ssl_loss: 1.7932, search_ppl: 0.5228, switch_ratio: 0.5833, vocab_util: 0.6667, t_search: 1, memory_span: 13\n",
      "Iteration 50/400 - loss: 6.8971, abs_loss: 5.1133, ssl_loss: 1.7838, search_ppl: 0.1122, switch_ratio: 0.5833, vocab_util: 0.7778, t_search: 1, memory_span: 13\n",
      "Iteration 51/400 - loss: 6.8458, abs_loss: 4.9976, ssl_loss: 1.8482, search_ppl: -0.2390, switch_ratio: 0.7917, vocab_util: 0.6667, t_search: 1, memory_span: 13\n",
      "Iteration 52/400 - loss: 6.1505, abs_loss: 4.1646, ssl_loss: 1.9859, search_ppl: 0.1392, switch_ratio: 0.5417, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 53/400 - loss: 5.4533, abs_loss: 3.4680, ssl_loss: 1.9852, search_ppl: 0.4868, switch_ratio: 0.5000, vocab_util: 0.7778, t_search: 1, memory_span: 13\n",
      "Iteration 54/400 - loss: 5.2195, abs_loss: 3.0856, ssl_loss: 2.1340, search_ppl: 0.2666, switch_ratio: 0.6667, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 55/400 - loss: 5.1206, abs_loss: 2.8245, ssl_loss: 2.2961, search_ppl: 0.6442, switch_ratio: 0.6667, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 56/400 - loss: 5.0760, abs_loss: 2.5707, ssl_loss: 2.5053, search_ppl: 0.8377, switch_ratio: 0.7500, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 57/400 - loss: 5.0301, abs_loss: 2.4544, ssl_loss: 2.5757, search_ppl: 0.5212, switch_ratio: 0.7917, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 58/400 - loss: 5.0104, abs_loss: 2.4084, ssl_loss: 2.6020, search_ppl: 0.7548, switch_ratio: 0.8750, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 59/400 - loss: 4.7614, abs_loss: 2.2836, ssl_loss: 2.4778, search_ppl: 0.5823, switch_ratio: 0.6250, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 60/400 - loss: 5.0178, abs_loss: 2.4272, ssl_loss: 2.5906, search_ppl: 0.5786, switch_ratio: 0.7083, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 61/400 - loss: 4.7961, abs_loss: 2.3672, ssl_loss: 2.4289, search_ppl: 0.3398, switch_ratio: 0.7500, vocab_util: 0.7778, t_search: 1, memory_span: 13\n",
      "Iteration 62/400 - loss: 4.6570, abs_loss: 2.3696, ssl_loss: 2.2874, search_ppl: 0.2772, switch_ratio: 0.5833, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 63/400 - loss: 4.5719, abs_loss: 2.3878, ssl_loss: 2.1842, search_ppl: 0.5599, switch_ratio: 0.7083, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 64/400 - loss: 4.4249, abs_loss: 2.3370, ssl_loss: 2.0879, search_ppl: 0.3743, switch_ratio: 0.5833, vocab_util: 0.8889, t_search: 1, memory_span: 13\n",
      "Iteration 65/400 - loss: 4.4598, abs_loss: 2.3939, ssl_loss: 2.0659, search_ppl: -0.0096, switch_ratio: 0.5833, vocab_util: 0.7778, t_search: 1, memory_span: 12\n",
      "Iteration 66/400 - loss: 4.6007, abs_loss: 2.4385, ssl_loss: 2.1622, search_ppl: 0.2936, switch_ratio: 0.5417, vocab_util: 0.8889, t_search: 1, memory_span: 12\n",
      "Iteration 67/400 - loss: 4.3168, abs_loss: 2.2501, ssl_loss: 2.0667, search_ppl: 0.1412, switch_ratio: 0.6667, vocab_util: 0.6667, t_search: 1, memory_span: 12\n",
      "Iteration 68/400 - loss: 4.2945, abs_loss: 2.2104, ssl_loss: 2.0841, search_ppl: 0.4272, switch_ratio: 0.6250, vocab_util: 0.8889, t_search: 1, memory_span: 12\n",
      "Iteration 69/400 - loss: 4.2648, abs_loss: 2.0930, ssl_loss: 2.1718, search_ppl: 0.3714, switch_ratio: 0.5417, vocab_util: 0.6667, t_search: 1, memory_span: 12\n",
      "Iteration 70/400 - loss: 4.0438, abs_loss: 1.8233, ssl_loss: 2.2205, search_ppl: 0.6255, switch_ratio: 0.3750, vocab_util: 0.7778, t_search: 1, memory_span: 12\n",
      "Iteration 71/400 - loss: 4.1254, abs_loss: 1.8427, ssl_loss: 2.2827, search_ppl: 0.6972, switch_ratio: 0.5417, vocab_util: 0.5556, t_search: 1, memory_span: 12\n",
      "Iteration 72/400 - loss: 3.7453, abs_loss: 1.5199, ssl_loss: 2.2254, search_ppl: 1.5086, switch_ratio: 0.4167, vocab_util: 0.3333, t_search: 1, memory_span: 12\n",
      "Iteration 73/400 - loss: 3.7300, abs_loss: 1.5392, ssl_loss: 2.1908, search_ppl: 1.5914, switch_ratio: 0.3333, vocab_util: 0.5556, t_search: 1, memory_span: 12\n",
      "Iteration 74/400 - loss: 4.0279, abs_loss: 1.9937, ssl_loss: 2.0342, search_ppl: 1.1154, switch_ratio: 0.5833, vocab_util: 0.7778, t_search: 1, memory_span: 12\n",
      "Iteration 75/400 - loss: 3.7433, abs_loss: 1.6161, ssl_loss: 2.1272, search_ppl: 1.8208, switch_ratio: 0.3750, vocab_util: 0.7778, t_search: 1, memory_span: 12\n",
      "Iteration 76/400 - loss: 3.2821, abs_loss: 1.1964, ssl_loss: 2.0857, search_ppl: 2.3574, switch_ratio: 0.2500, vocab_util: 0.4444, t_search: 1, memory_span: 12\n",
      "Iteration 77/400 - loss: 3.6488, abs_loss: 1.5137, ssl_loss: 2.1351, search_ppl: 3.0726, switch_ratio: 0.2917, vocab_util: 0.6667, t_search: 1, memory_span: 12\n",
      "Iteration 78/400 - loss: 3.3405, abs_loss: 1.3043, ssl_loss: 2.0361, search_ppl: 2.3350, switch_ratio: 0.2917, vocab_util: 0.6667, t_search: 1, memory_span: 12\n",
      "Iteration 79/400 - loss: 3.6699, abs_loss: 1.6130, ssl_loss: 2.0569, search_ppl: 1.6873, switch_ratio: 0.4167, vocab_util: 0.5556, t_search: 1, memory_span: 12\n",
      "Iteration 80/400 - loss: 3.5788, abs_loss: 1.5997, ssl_loss: 1.9791, search_ppl: 1.1305, switch_ratio: 0.4167, vocab_util: 0.4444, t_search: 1, memory_span: 12\n",
      "Iteration 81/400 - loss: 3.4317, abs_loss: 1.4239, ssl_loss: 2.0078, search_ppl: 0.7980, switch_ratio: 0.3333, vocab_util: 0.5556, t_search: 1, memory_span: 11\n",
      "Iteration 82/400 - loss: 3.1978, abs_loss: 1.1852, ssl_loss: 2.0126, search_ppl: 0.5734, switch_ratio: 0.4167, vocab_util: 0.3333, t_search: 1, memory_span: 11\n",
      "Iteration 83/400 - loss: 3.1993, abs_loss: 1.1794, ssl_loss: 2.0199, search_ppl: 1.0280, switch_ratio: 0.2917, vocab_util: 0.3333, t_search: 1, memory_span: 11\n",
      "Iteration 84/400 - loss: 2.6855, abs_loss: 0.6066, ssl_loss: 2.0788, search_ppl: 0.7138, switch_ratio: 0.0417, vocab_util: 0.2222, t_search: 1, memory_span: 11\n",
      "Iteration 85/400 - loss: 2.9882, abs_loss: 0.8828, ssl_loss: 2.1054, search_ppl: 1.3721, switch_ratio: 0.2083, vocab_util: 0.3333, t_search: 1, memory_span: 11\n",
      "Iteration 86/400 - loss: 3.2465, abs_loss: 1.0986, ssl_loss: 2.1479, search_ppl: 1.9951, switch_ratio: 0.2500, vocab_util: 0.4444, t_search: 1, memory_span: 11\n",
      "Iteration 87/400 - loss: 3.1789, abs_loss: 1.0625, ssl_loss: 2.1164, search_ppl: 2.5778, switch_ratio: 0.2917, vocab_util: 0.5556, t_search: 1, memory_span: 11\n",
      "Iteration 88/400 - loss: 2.8793, abs_loss: 0.7759, ssl_loss: 2.1034, search_ppl: 2.9306, switch_ratio: 0.1667, vocab_util: 0.3333, t_search: 1, memory_span: 11\n",
      "Iteration 89/400 - loss: 2.8395, abs_loss: 0.7389, ssl_loss: 2.1006, search_ppl: 3.2532, switch_ratio: 0.1667, vocab_util: 0.3333, t_search: 1, memory_span: 11\n",
      "Iteration 90/400 - loss: 2.3824, abs_loss: 0.3251, ssl_loss: 2.0573, search_ppl: 3.3695, switch_ratio: 0.0000, vocab_util: 0.2222, t_search: 1, memory_span: 11\n",
      "Iteration 91/400 - loss: 2.4437, abs_loss: 0.3631, ssl_loss: 2.0806, search_ppl: 5.0091, switch_ratio: 0.0417, vocab_util: 0.2222, t_search: 1, memory_span: 11\n",
      "Iteration 92/400 - loss: 2.5951, abs_loss: 0.6023, ssl_loss: 1.9928, search_ppl: 2.9022, switch_ratio: 0.0833, vocab_util: 0.3333, t_search: 1, memory_span: 11\n",
      "Iteration 93/400 - loss: 2.3345, abs_loss: 0.3652, ssl_loss: 1.9693, search_ppl: 4.2505, switch_ratio: 0.0833, vocab_util: 0.2222, t_search: 1, memory_span: 11\n",
      "Iteration 94/400 - loss: 2.4259, abs_loss: 0.5157, ssl_loss: 1.9102, search_ppl: 4.2884, switch_ratio: 0.0833, vocab_util: 0.3333, t_search: 1, memory_span: 11\n",
      "Iteration 95/400 - loss: 2.3056, abs_loss: 0.4574, ssl_loss: 1.8482, search_ppl: 3.6544, switch_ratio: 0.0833, vocab_util: 0.2222, t_search: 1, memory_span: 11\n",
      "Iteration 96/400 - loss: 2.4667, abs_loss: 0.6714, ssl_loss: 1.7954, search_ppl: 3.4691, switch_ratio: 0.0833, vocab_util: 0.4444, t_search: 1, memory_span: 11\n",
      "Iteration 97/400 - loss: 5.0515, abs_loss: 3.0922, ssl_loss: 1.9593, search_ppl: 3.2358, switch_ratio: 0.5417, vocab_util: 0.7778, t_search: 2, memory_span: 10\n",
      "Iteration 98/400 - loss: 4.9653, abs_loss: 2.9084, ssl_loss: 2.0568, search_ppl: 3.5758, switch_ratio: 0.5833, vocab_util: 0.6667, t_search: 2, memory_span: 10\n",
      "Iteration 99/400 - loss: 4.4267, abs_loss: 2.4376, ssl_loss: 1.9891, search_ppl: 4.4493, switch_ratio: 0.4167, vocab_util: 0.7778, t_search: 2, memory_span: 10\n",
      "Iteration 100/400 - loss: 4.3645, abs_loss: 2.3156, ssl_loss: 2.0489, search_ppl: 3.5762, switch_ratio: 0.4583, vocab_util: 0.6667, t_search: 2, memory_span: 10\n",
      "Iteration 101/400 - loss: 3.8312, abs_loss: 1.5358, ssl_loss: 2.2955, search_ppl: 2.7435, switch_ratio: 0.3333, vocab_util: 0.4444, t_search: 2, memory_span: 10\n",
      "Iteration 102/400 - loss: 3.7701, abs_loss: 1.5498, ssl_loss: 2.2204, search_ppl: 5.0778, switch_ratio: 0.2500, vocab_util: 0.6667, t_search: 2, memory_span: 10\n",
      "Iteration 103/400 - loss: 3.2835, abs_loss: 1.0835, ssl_loss: 2.2000, search_ppl: 3.3566, switch_ratio: 0.3750, vocab_util: 0.5556, t_search: 2, memory_span: 10\n",
      "Iteration 104/400 - loss: 3.3976, abs_loss: 1.0651, ssl_loss: 2.3325, search_ppl: 0.9994, switch_ratio: 0.3750, vocab_util: 0.5556, t_search: 2, memory_span: 10\n",
      "Iteration 105/400 - loss: 3.4567, abs_loss: 0.9571, ssl_loss: 2.4996, search_ppl: 4.3302, switch_ratio: 0.3333, vocab_util: 0.5556, t_search: 2, memory_span: 10\n",
      "Iteration 106/400 - loss: 3.2746, abs_loss: 0.8943, ssl_loss: 2.3803, search_ppl: 4.4130, switch_ratio: 0.3750, vocab_util: 0.5556, t_search: 2, memory_span: 10\n",
      "Iteration 107/400 - loss: 3.4062, abs_loss: 1.1469, ssl_loss: 2.2593, search_ppl: 5.1963, switch_ratio: 0.4583, vocab_util: 0.8889, t_search: 2, memory_span: 10\n",
      "Iteration 108/400 - loss: 3.2802, abs_loss: 1.0653, ssl_loss: 2.2149, search_ppl: 5.2707, switch_ratio: 0.4167, vocab_util: 0.7778, t_search: 2, memory_span: 10\n",
      "Iteration 109/400 - loss: 3.3726, abs_loss: 1.1048, ssl_loss: 2.2678, search_ppl: 4.4109, switch_ratio: 0.4583, vocab_util: 0.6667, t_search: 2, memory_span: 10\n",
      "Iteration 110/400 - loss: 3.0942, abs_loss: 0.8926, ssl_loss: 2.2017, search_ppl: 3.0572, switch_ratio: 0.2500, vocab_util: 0.4444, t_search: 2, memory_span: 10\n"
     ]
    }
   ],
   "source": [
    "from src.sorl import SearchScheduler, sorl_search, compute_loss, evaluate, compute_vocab_utilization_rate\n",
    "import torch \n",
    "from dataset.base import get_batch\n",
    "\n",
    "start_step = 0 \n",
    "config = sorl_config\n",
    "\n",
    "optimizer = torch.optim.Adam(gat.parameters(), lr=config.learning_rate)\n",
    "scheduler = SearchScheduler(config, gat.K)\n",
    "\n",
    "for i in range(config.train_iterations):\n",
    "    # config.temperature = 0.0 if i % 2 == 0 else 1.0\n",
    "    global_step = start_step + i\n",
    "    gat.train() \n",
    "\n",
    "    t_search = scheduler.step()\n",
    "    config.max_t_search = t_search # incremental abstraction search\n",
    "    gat.memory_span = scheduler.memory_span # memory fading\n",
    "\n",
    "    data = get_batch(train_dataset, config.train_batch_size, config.max_length, gat.level_mask_tokens[0], device=gat.device)\n",
    "\n",
    "    with torch.no_grad(): \n",
    "\n",
    "        search_data, switch_ratio = sorl_search(data, gat, config)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    ppt = gat(search_data[:, :-1].contiguous(), target=search_data[:, 1:].contiguous())\n",
    "\n",
    "    ssl_loss, abs_loss = compute_loss(search_data, gat, ppt)\n",
    "    loss = abs_loss + ssl_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Validation needs to be more rigorous : more samples\n",
    "    gat.eval()\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        _, improve_ppl_train, _, _ = evaluate(data, gat, 5, config)\n",
    "        vocab_utilization_rate = compute_vocab_utilization_rate(search_data, gat)\n",
    "\n",
    "    print(f\"Iteration {i+1}/{config.train_iterations} \"\n",
    "                    f\"- loss: {loss.item():.4f}, abs_loss: {abs_loss.item():.4f}, ssl_loss: {ssl_loss.item():.4f}, search_ppl: {improve_ppl_train.item():.4f}, switch_ratio: {switch_ratio:.4f}, vocab_util: {vocab_utilization_rate:.4f}, t_search: {t_search}, memory_span: {gat.memory_span}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (A). no curriculum | temperature flip |  ppl_improve: 15. | abs loss ~ 0.0\n",
    "# (B). curriculum | temperature flip | ppl_improve: 26. | abs loss ~ 0.0\n",
    "# Conclusion: curriculum helps improve the search ability of the model. \n",
    "\n",
    "# (C). curriculum | no temperature flip, temperature=1.0 | ppl_improve: 0.15 | abs loss: 1.33\n",
    "# Conclusion: temperature flip stabilizes abstraction (we just need more push towards convergence)\n",
    "\n",
    "# (D). curriculum | disallow spike placeholders | ppl_improve: 9.6 | abs_loss: 0.55 | vocab_utilization_rate: 0.22\n",
    "# (E). curriculum | allow spike placeholders | ppl_improve: 13.8 | abs_loss: 0.6 | vocab_utilization_rate: 0.22\n",
    "# Conclusion: it's hard to tell the effect of spike-placeholders here, but vocab_utilization is an issue\n",
    "\n",
    "# (F). curriculum | temperature=0.5 | ppl_improve: 30.6 | abs_loss: ~0.0 | vocab utilization 0.2 (flucturate a bit)\n",
    "# (G). curriculum | temperature=0.75 | ppl_improve: 15.9 | abs_loss: 0.46 | vocab utilization 0.33 ~ 0.44 \n",
    "\n",
    "# Q. what about the perplexity-placeholder? Does it help? \n",
    "# Q. how about memory fading? Can it work? \n",
    "# Q. can we measure 'vocabulary utilization rate'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# compute abstract utilization rate\n",
    "# search_data <=\n",
    "si, ei = gat.vocab_sizes.cumsum(dim=0) # begin_idx, end_idx\n",
    "\n",
    "vocab_utilization_rate = search_data[(search_data >= si) & (search_data < ei)].unique().size(0) / (ei - si).item()\n",
    "\n",
    "\n",
    "vocab_utilization_rate = data[(data >= si) & (data < ei)].unique().size(0) / (ei - si).item()\n",
    "\n",
    "vocab_utilization_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
